{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. ChatMessageHistory的使用\n",
   "id": "969f04d315d59853"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 场景1: 记忆存储",
   "id": "b8c1f1cc19a312d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T14:11:04.967243Z",
     "start_time": "2025-10-10T14:11:03.907298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "history =  ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"你好\")\n",
    "\n",
    "history.add_ai_message(\"很高兴认识你\")\n",
    "\n",
    "print(history.messages)\n"
   ],
   "id": "18dd5c6cbec1f81b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 场景2: 对接LLM",
   "id": "6c55158c70329dbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T14:15:16.230726Z",
     "start_time": "2025-10-10T14:15:12.730621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import dotenv\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name = os.getenv(\"MODEL\"),\n",
    "    base_url = os.getenv(\"BASE_URL\"),\n",
    "    api_key = os.getenv(\"ARK_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "history =  ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"你好\")\n",
    "\n",
    "history.add_ai_message(\"很高兴认识你\")\n",
    "\n",
    "history.add_user_message(\"帮我计算1 + 2 + 3 = ?\")\n",
    "\n",
    "response = chat_model.invoke(history.messages)\n",
    "\n",
    "print(response.content)\n"
   ],
   "id": "6d843df89fb152cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按照数学运算顺序，从左到右依次计算：\n",
      "先计算1 + 2 = 3，再计算3 + 3 = 6。\n",
      "\n",
      "所以1 + 2 + 3的结果是6。 \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. ConversationBufferMemory\n",
    "\n",
    "- 适用场景：对话轮次较少、依赖完整上下文的场景（如简单的聊天机器）\n",
    "- 特点：\n",
    "    - 完整存储对话历史\n",
    "    - 简单 、 无裁剪 、 无压缩\n",
    "    - 与 Chains/Models 无缝集成\n",
    "    - 支持两种返回格式（通过 return_messages 参数控制输出格式）\n",
    "        - return_messages=True 返回消息对象列表（ List[BaseMessage]\n",
    "        - return_messages=False （默认） 返回拼接的 纯文本字符串\n",
    "\n"
   ],
   "id": "af5f491d7b93ee1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例1: 以字符串的方式返回存储的信息",
   "id": "1e05de6834b3cdd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T14:26:07.069236Z",
     "start_time": "2025-10-10T14:26:07.052047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "memory.save_context(inputs={\"input\":\"你好，我叫小明\"},outputs = {\"output\":\"很高兴认识你\"})\n",
    "\n",
    "memory.save_context(inputs={\"input\":\"请帮我回到一下1 + 2 * 3 = ?\"},outputs={\"output\":\"7\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    " "
   ],
   "id": "e5bd3bee1911c607",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好，我叫小明\\nAI: 很高兴认识你\\nHuman: 请帮我回到一下1 + 2 * 3 = ?\\nAI: 7'}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例2: 以消息列表的方式返回存储的消息",
   "id": "bcdb84979784ba00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T14:31:47.387159Z",
     "start_time": "2025-10-10T14:31:47.377364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context(inputs={\"input\":\"你好，我叫小明\"},outputs = {\"output\":\"很高兴认识你\"})\n",
    "\n",
    "memory.save_context(inputs={\"input\":\"请帮我回到一下1 + 2 * 3 = ?\"},outputs={\"output\":\"7\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(memory.chat_memory.messages)\n",
    " "
   ],
   "id": "79cae51fd15cd2eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='你好，我叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={}), HumanMessage(content='请帮我回到一下1 + 2 * 3 = ?', additional_kwargs={}, response_metadata={}), AIMessage(content='7', additional_kwargs={}, response_metadata={})]}\n",
      "\n",
      "\n",
      "[HumanMessage(content='你好，我叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={}), HumanMessage(content='请帮我回到一下1 + 2 * 3 = ?', additional_kwargs={}, response_metadata={}), AIMessage(content='7', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例3: 结合大模型、提示词模版的使用(promptTemplate)",
   "id": "6567dbdf38b24544"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T13:51:01.392662Z",
     "start_time": "2025-10-11T13:51:00.413043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import dotenv\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core. prompts. prompt import PromptTemplate\n",
    "from langchain. memory. buffer import ConversationBufferMemory\n",
    "from langchain. chains. llm import LLMChain\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name = os.getenv(\"MODEL\"),\n",
    "    base_url = os.getenv(\"BASE_URL\"),\n",
    "    api_key = os.getenv(\"ARK_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt_template =  PromptTemplate.from_template(\n",
    "    template = \"\"\"\n",
    "    你可以与人类对话,\n",
    "    当前对话历史:{history},\n",
    "    人类问题:{question},\n",
    "    回复:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "memory =  ConversationBufferMemory()\n",
    "\n",
    "chain =  LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\n",
    "\n",
    "response =  chain.invoke({\"question\":\"我叫小明\"})\n",
    "\n",
    "print(response)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "90a92987ea2765be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我叫小明', 'history': '', 'text': '你好，小明！很高兴认识你，有什么想聊的都可以跟我说哦。 '}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T13:52:33.266217Z",
     "start_time": "2025-10-11T13:52:31.850112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response =  chain.invoke({\"question\":\"我叫什么名字呢？\"})\n",
    "\n",
    "print(response)\n"
   ],
   "id": "adf2133d9763a132",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我叫什么名字呢？', 'history': 'Human: 我叫小明\\nAI: 你好，小明！很高兴认识你，有什么想聊的都可以跟我说哦。 ', 'text': '你叫小明，我记住你的名字啦。要是还有别的话题，也能随时和我分享。 '}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例4: 基于举例3，显示设置memory的key的值",
   "id": "708c7c35a208c699"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T13:58:14.505315Z",
     "start_time": "2025-10-11T13:58:13.315441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import dotenv\n",
    "from langchain_core. prompts. prompt import PromptTemplate\n",
    "from langchain. memory. buffer import ConversationBufferMemory\n",
    "from langchain. chains. llm import LLMChain\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name = os.getenv(\"MODEL\"),\n",
    "    base_url = os.getenv(\"BASE_URL\"),\n",
    "    api_key = os.getenv(\"ARK_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt_template =  PromptTemplate.from_template(\n",
    "    template = \"\"\"\n",
    "    你可以与人类对话,\n",
    "    当前对话历史:{chat_history},\n",
    "    人类问题:{question},\n",
    "    回复:\n",
    "    \"\"\"\n",
    ")\n",
    "memory =  ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "chain =  LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\n",
    "\n",
    "response =  chain.invoke({\"question\":\"我叫小明\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "d346377bb01c2d0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我叫小明', 'chat_history': '', 'text': '你好，小明！很高兴认识你，有什么想聊的都可以跟我说。 '}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T14:01:48.631078Z",
     "start_time": "2025-10-11T14:01:47.563731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response =  chain.invoke({\"question\":\"我叫什么名字呢？\"})\n",
    "print(response)"
   ],
   "id": "86efb161ee7ff10c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我叫什么名字呢？', 'chat_history': 'Human: 我叫小明\\nAI: 你好，小明！很高兴认识你，有什么想聊的都可以跟我说。 \\nHuman: 我叫什么名字呢？\\nAI: 你叫小明，你之前已经告诉过我啦。', 'text': '你叫小明呀，我一直都记得呢。 '}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例5: 结合大模型、提示词模版的使用(ChatPromptTemplate)",
   "id": "de31ebae760d275b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T14:10:27.280257Z",
     "start_time": "2025-10-11T14:10:25.901020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import dotenv\n",
    "from langchain_core. prompts. prompt import PromptTemplate\n",
    "from langchain. memory. buffer import ConversationBufferMemory\n",
    "from langchain. chains. llm import LLMChain\n",
    "from langchain_core. prompts. chat import ChatPromptTemplate\n",
    "from langchain_core. prompts. chat import MessagesPlaceholder\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name = os.getenv(\"MODEL\"),\n",
    "    base_url = os.getenv(\"BASE_URL\"),\n",
    "    api_key = os.getenv(\"ARK_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt_template =  ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"你是一个与人类对话的机器人\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\",\"问题:{question}\")\n",
    "    \n",
    "]\n",
    ")\n",
    "memory =  ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "chain =  LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\n",
    "\n",
    "response =  chain.invoke({\"question\":\"我叫小明\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "5df3485e0bb11396",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我叫小明', 'history': [HumanMessage(content='我叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='你好呀，小明！很高兴认识你，要是你有什么想聊的话题、有什么问题，都可以随时跟我说。 ', additional_kwargs={}, response_metadata={})], 'text': '你好呀，小明！很高兴认识你，要是你有什么想聊的话题、有什么问题，都可以随时跟我说。 '}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T14:10:54.150391Z",
     "start_time": "2025-10-11T14:10:53.041420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response =  chain.invoke({\"question\":\"我叫什么名字呢？\"})\n",
    "print(response)"
   ],
   "id": "17e15d5477a6944a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我叫什么名字呢？', 'history': [HumanMessage(content='我叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='你好呀，小明！很高兴认识你，要是你有什么想聊的话题、有什么问题，都可以随时跟我说。 ', additional_kwargs={}, response_metadata={}), HumanMessage(content='我叫什么名字呢？', additional_kwargs={}, response_metadata={}), AIMessage(content='你叫小明，刚刚你已经告诉过我啦。', additional_kwargs={}, response_metadata={})], 'text': '你叫小明，刚刚你已经告诉过我啦。'}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. ConversationChain的使用",
   "id": "71111ff062cd76ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例1: 以PromptTemplate为例",
   "id": "58242e76c263c88e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T14:29:07.555455Z",
     "start_time": "2025-10-11T14:29:06.218652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import dotenv\n",
    "from langchain_core. prompts. prompt import PromptTemplate\n",
    "from langchain. chains. conversation. base import ConversationChain\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name = os.getenv(\"MODEL\"),\n",
    "    base_url = os.getenv(\"BASE_URL\"),\n",
    "    api_key = os.getenv(\"ARK_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt_template =  PromptTemplate.from_template(\n",
    "    template = \"\"\"\n",
    "    你可以与人类对话,\n",
    "    当前对话历史:{history},\n",
    "    人类问题:{input},\n",
    "    回复:\n",
    "    \"\"\"\n",
    ")\n",
    "# memory =  ConversationBufferMemory(return_messages=True)\n",
    "# \n",
    "# chain =  LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\n",
    "\n",
    "# 创建ConversationChain的实例\n",
    "chain = ConversationChain(llm=chat_model, prompt=prompt_template)\n",
    "\n",
    "response =  chain.invoke({\"input\":\"我叫小明\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "748ce99bf4d56296",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '我叫小明', 'history': '', 'response': '你好，小明！很高兴认识你，有什么想聊的都可以跟我说。 '}\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T14:29:35.088053Z",
     "start_time": "2025-10-11T14:29:34.007556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response =  chain.invoke({\"input\":\"我叫什么名字呢？\"})\n",
    "print(response)"
   ],
   "id": "7973788df28f3377",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '我叫什么名字呢？', 'history': 'Human: 我叫小明\\nAI: 你好，小明！很高兴认识你，有什么想聊的都可以跟我说。 ', 'response': '你叫小明，之前你已经告诉过我啦。'}\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例2: 使用默认的提示词模版",
   "id": "35637c2e046dca6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T05:43:51.365747Z",
     "start_time": "2025-10-12T05:43:49.504387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import dotenv\n",
    "from langchain_core. prompts. prompt import PromptTemplate\n",
    "from langchain. chains. conversation. base import ConversationChain\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name = os.getenv(\"MODEL\"),\n",
    "    base_url = os.getenv(\"BASE_URL\"),\n",
    "    api_key = os.getenv(\"ARK_API_KEY\"),\n",
    ")\n",
    "\n",
    "# prompt_template =  PromptTemplate.from_template(\n",
    "#     template = \"\"\"\n",
    "#     你可以与人类对话,\n",
    "#     当前对话历史:{history},\n",
    "#     人类问题:{input},\n",
    "#     回复:\n",
    "#     \"\"\"\n",
    "# )\n",
    "# memory =  ConversationBufferMemory(return_messages=True)\n",
    "# \n",
    "# chain =  LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\n",
    "\n",
    "# 创建ConversationChain的实例\n",
    "chain = ConversationChain(llm=chat_model)\n",
    "\n",
    "response =  chain.invoke({\"input\":\"我叫小明\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "55ea46ba219f9e52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '我叫小明', 'history': '', 'response': '你好呀，小明！很高兴认识你。能和我分享一些你生活里有趣的事儿吗，比如你平时有什么特别喜欢的爱好呀？ '}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T05:44:07.295220Z",
     "start_time": "2025-10-12T05:44:05.632090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response =  chain.invoke({\"input\":\"我叫什么？\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "31a1a70c6515b904",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '我叫什么？', 'history': 'Human: 我叫小明\\nAI: 你好呀，小明！很高兴认识你。能和我分享一些你生活里有趣的事儿吗，比如你平时有什么特别喜欢的爱好呀？ ', 'response': '你叫小明呀，我记住啦！你要是还有其他想聊的，不管是生活趣事、兴趣爱好，都能接着和我说呢。 '}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. ConversationBufferWindowMemory的使用",
   "id": "9017f1bdb7b2b86c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例1:",
   "id": "ff42e78dd7ee51ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T06:03:14.216580Z",
     "start_time": "2025-10-12T06:03:14.206024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k = 2)\n",
    "\n",
    "memory.save_context({\"input\":\"你好\"},{\"output\":\"怎么了\"})\n",
    "memory.save_context({\"input\":\"你是谁\"},{\"output\":\"我是AI助手\"})\n",
    "memory.save_context({\"input\":\"你的生日是哪天\"},{\"output\":\"我不清楚\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))\n"
   ],
   "id": "791eba8ac059d34d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你是谁\\nAI: 我是AI助手\\nHuman: 你的生日是哪天\\nAI: 我不清楚'}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例2: 返回消息构成的上下文记忆",
   "id": "8b5467ffeb7d1511"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T06:04:05.233686Z",
     "start_time": "2025-10-12T06:04:05.222614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k = 2,return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\":\"你好\"},{\"output\":\"怎么了\"})\n",
    "memory.save_context({\"input\":\"你是谁\"},{\"output\":\"我是AI助手\"})\n",
    "memory.save_context({\"input\":\"你的生日是哪天\"},{\"output\":\"我不清楚\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))\n"
   ],
   "id": "e22019175f8d18c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='你是谁', additional_kwargs={}, response_metadata={}), AIMessage(content='我是AI助手', additional_kwargs={}, response_metadata={}), HumanMessage(content='你的生日是哪天', additional_kwargs={}, response_metadata={}), AIMessage(content='我不清楚', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例3: 结合llm,chain的使用",
   "id": "86569fe771d37eb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T06:08:37.680836Z",
     "start_time": "2025-10-12T06:08:30.736245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 1. 定义对话模板\n",
    "template = \"\"\"以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
    "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
    "\n",
    "当前对话：\n",
    "{history}\n",
    "Human: {question}\n",
    "AI:\"\"\"\n",
    "\n",
    "# 2. 创建提示词模板\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# 3. 初始化大模型 (注意：当前OpenAI没有\"gpt-4o-mini\"模型，建议使用\"gpt-3.5-turbo\"或\"gpt-4\")\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name = os.getenv(\"MODEL\"),\n",
    "    base_url = os.getenv(\"BASE_URL\"),\n",
    "    api_key = os.getenv(\"ARK_API_KEY\"),\n",
    ")\n",
    "\n",
    "# 4. 实例化带窗口的记忆 (k=1表示只保留最近1轮对话)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "# 5. 创建对话链\n",
    "conversation_with_summary = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt_template,\n",
    "    memory=memory,\n",
    "    verbose=True  # 开启详细日志\n",
    ")\n",
    "\n",
    "# 6. 测试对话流程\n",
    "# 第一次提问 - 提供名字\n",
    "respon1 = conversation_with_summary.invoke({\"question\": \"你好，我是孙小空\"})\n",
    "print(\"第一次回复:\", respon1['text'])\n",
    "\n",
    "# 第二次提问 - 提供师弟信息\n",
    "respon2 = conversation_with_summary.invoke({\"question\": \"我还有两个师弟，一个是猪小戒，一个是沙小僧\"})\n",
    "print(\"\\n第二次回复:\", respon2['text'])\n",
    "\n",
    "# 第三次提问 - 高考信息\n",
    "respon3 = conversation_with_summary.invoke({\"question\": \"我今年高考，竟然考上了1本\"})\n",
    "print(\"\\n第三次回复:\", respon3['text'])\n",
    "\n",
    "# 第四次提问 - 测试记忆 (由于k=1，这里只能记住最后一次对话)\n",
    "respon4 = conversation_with_summary.invoke({\"question\": \"我叫什么？\"})\n",
    "print(\"\\n第四次回复:\", respon4['text'])"
   ],
   "id": "9faf311819224c0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "\n",
      "Human: 你好，我是孙小空\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "第一次回复: 你好呀孙小空，很高兴认识你！要是你有什么想聊的话题，不管是电影、书籍、科技，还是其他方面的，都能跟我说一说。 \n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 你好，我是孙小空\n",
      "AI: 你好呀孙小空，很高兴认识你！要是你有什么想聊的话题，不管是电影、书籍、科技，还是其他方面的，都能跟我说一说。 \n",
      "Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "第二次回复: 哇，感觉你们的名字很有特色呢，让我一下就联想到了《西游记》里的孙悟空、猪八戒和沙僧。你们是不是也像他们一样有很多有趣的冒险故事呀？能和我说说你们一起经历过的好玩的事儿不？ \n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\n",
      "AI: 哇，感觉你们的名字很有特色呢，让我一下就联想到了《西游记》里的孙悟空、猪八戒和沙僧。你们是不是也像他们一样有很多有趣的冒险故事呀？能和我说说你们一起经历过的好玩的事儿不？ \n",
      "Human: 我今年高考，竟然考上了1本\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "第三次回复: 恭喜恭喜呀！考上一本可是非常厉害的事情，这背后一定有你付出的无数努力呢。能跟我说说你查到成绩那一刻的心情吗？还有你有没有心仪的大学和专业呀？ \n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 我今年高考，竟然考上了1本\n",
      "AI: 恭喜恭喜呀！考上一本可是非常厉害的事情，这背后一定有你付出的无数努力呢。能跟我说说你查到成绩那一刻的心情吗？还有你有没有心仪的大学和专业呀？ \n",
      "Human: 我叫什么？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "第四次回复: 不知道。\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例4: 修改举例3中的参数k",
   "id": "d212ed1968415147"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T06:13:27.708992Z",
     "start_time": "2025-10-12T06:13:18.167063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 1. 定义对话模板\n",
    "template = \"\"\"以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
    "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
    "\n",
    "当前对话：\n",
    "{history}\n",
    "Human: {question}\n",
    "AI:\"\"\"\n",
    "\n",
    "# 2. 创建提示词模板\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# 3. 初始化大模型 (注意：当前OpenAI没有\"gpt-4o-mini\"模型，建议使用\"gpt-3.5-turbo\"或\"gpt-4\")\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name = os.getenv(\"MODEL\"),\n",
    "    base_url = os.getenv(\"BASE_URL\"),\n",
    "    api_key = os.getenv(\"ARK_API_KEY\"),\n",
    ")\n",
    "\n",
    "# 4. 实例化带窗口的记忆 (k=1表示只保留最近1轮对话)\n",
    "memory = ConversationBufferWindowMemory(k=3)\n",
    "\n",
    "# 5. 创建对话链\n",
    "conversation_with_summary = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt_template,\n",
    "    memory=memory,\n",
    "    verbose=True  # 开启详细日志\n",
    ")\n",
    "\n",
    "# 6. 测试对话流程\n",
    "# 第一次提问 - 提供名字\n",
    "respon1 = conversation_with_summary.invoke({\"question\": \"你好，我是孙小空\"})\n",
    "print(\"第一次回复:\", respon1['text'])\n",
    "\n",
    "# 第二次提问 - 提供师弟信息\n",
    "respon2 = conversation_with_summary.invoke({\"question\": \"我还有两个师弟，一个是猪小戒，一个是沙小僧\"})\n",
    "print(\"\\n第二次回复:\", respon2['text'])\n",
    "\n",
    "# 第三次提问 - 高考信息\n",
    "respon3 = conversation_with_summary.invoke({\"question\": \"我今年高考，竟然考上了1本\"})\n",
    "print(\"\\n第三次回复:\", respon3['text'])\n",
    "\n",
    "# 第四次提问 - 测试记忆 (由于k=1，这里只能记住最后一次对话)\n",
    "respon4 = conversation_with_summary.invoke({\"question\": \"我叫什么？\"})\n",
    "print(\"\\n第四次回复:\", respon4['text'])"
   ],
   "id": "6a04567de9350702",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "\n",
      "Human: 你好，我是孙小空\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "第一次回复: 你好呀孙小空，很高兴认识你！有什么问题都可以随时问我呢，不管是天文地理，还是生活琐事，我都会尽力提供详细的解答。 \n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 你好，我是孙小空\n",
      "AI: 你好呀孙小空，很高兴认识你！有什么问题都可以随时问我呢，不管是天文地理，还是生活琐事，我都会尽力提供详细的解答。 \n",
      "Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "第二次回复: 哇，这名字听起来很有《西游记》的感觉呢！猪小戒对应猪八戒，沙小僧对应沙僧，而你孙小空自然就是对应孙悟空啦。你们这组合感觉就像一支充满奇幻色彩的小队伍，能跟我说说你们平时会一起做些什么有趣的事儿吗？ \n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 你好，我是孙小空\n",
      "AI: 你好呀孙小空，很高兴认识你！有什么问题都可以随时问我呢，不管是天文地理，还是生活琐事，我都会尽力提供详细的解答。 \n",
      "Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\n",
      "AI: 哇，这名字听起来很有《西游记》的感觉呢！猪小戒对应猪八戒，沙小僧对应沙僧，而你孙小空自然就是对应孙悟空啦。你们这组合感觉就像一支充满奇幻色彩的小队伍，能跟我说说你们平时会一起做些什么有趣的事儿吗？ \n",
      "Human: 我今年高考，竟然考上了1本\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "第三次回复: 恭喜你呀孙小空，考上一本可是非常棒的成绩呢，这一定是你平时努力学习的结果。能和我说说你考上了哪所大学吗？或者接下来你对大学生涯有什么样的期待和规划不？是打算加入社团、参加各种活动，还是专注于学术研究呢？ \n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的\n",
      "具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 你好，我是孙小空\n",
      "AI: 你好呀孙小空，很高兴认识你！有什么问题都可以随时问我呢，不管是天文地理，还是生活琐事，我都会尽力提供详细的解答。 \n",
      "Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\n",
      "AI: 哇，这名字听起来很有《西游记》的感觉呢！猪小戒对应猪八戒，沙小僧对应沙僧，而你孙小空自然就是对应孙悟空啦。你们这组合感觉就像一支充满奇幻色彩的小队伍，能跟我说说你们平时会一起做些什么有趣的事儿吗？ \n",
      "Human: 我今年高考，竟然考上了1本\n",
      "AI: 恭喜你呀孙小空，考上一本可是非常棒的成绩呢，这一定是你平时努力学习的结果。能和我说说你考上了哪所大学吗？或者接下来你对大学生涯有什么样的期待和规划不？是打算加入社团、参加各种活动，还是专注于学术研究呢？ \n",
      "Human: 我叫什么？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "第四次回复: 你叫孙小空呀，你一开始就告诉我啦。 \n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
