{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. CharacterTextSplitter: Split by character",
   "id": "17b58dfe7be9838a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T08:32:44.498387Z",
     "start_time": "2025-10-19T08:32:43.757411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入相关依赖\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from markdown_it.rules_block import paragraph\n",
    "\n",
    "# 2. 示例文本（包含中英文混合内容）\n",
    "text = \"\"\"\n",
    "LangChain 是一个用于开发由语言模型驱动的应用程序的框架。\n",
    "它提供了一套工具和抽象，使开发者能够更容易地构建复杂的应用程序。\n",
    "\"\"\"\n",
    "\n",
    "# 3. 定义字符分割器\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=50,          # 每个文本块的最大字符数（按Unicode字符计算）\n",
    "    chunk_overlap=5,        # 块与块之间的重叠字符数（避免语义断裂）\n",
    "    separator=\"\",           # 禁用分隔符优先（设为空字符串表示纯字符分割）\n",
    "    length_function=len,    # 使用Python内置len函数计算长度（默认值，可省略）\n",
    "    is_separator_regex=False  # 分隔符是否为正则表达式（默认为False）\n",
    ")\n",
    "\n",
    "# 4. 分割文本\n",
    "text_chunks = splitter.split_text(text.strip())  # 先去除首尾空白再分割\n",
    "\n",
    "# 5. 打印结果（带详细统计信息）\n",
    "print(f\"原始文本长度：{len(text.strip())} 字符\")\n",
    "print(f\"分割后得到 {len(text_chunks)} 个文本块：\\n\")\n",
    "\n",
    "for i, chunk in enumerate(text_chunks, start=1):\n",
    "    print(f\"┌{'─' * 50}\")\n",
    "    print(f\"│ 块 {i}: 长度={len(chunk)} 字符\")\n",
    "    print(f\"├{'─' * 50}\")\n",
    "    print(f\"│ {chunk}\")\n",
    "    print(f\"└{'─' * 50}\\n\")"
   ],
   "id": "4032cfdc179ec353",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本长度：66 字符\n",
      "分割后得到 2 个文本块：\n",
      "\n",
      "┌──────────────────────────────────────────────────\n",
      "│ 块 1: 长度=50 字符\n",
      "├──────────────────────────────────────────────────\n",
      "│ LangChain 是一个用于开发由语言模型驱动的应用程序的框架。\n",
      "它提供了一套工具和抽象，使开发者\n",
      "└──────────────────────────────────────────────────\n",
      "\n",
      "┌──────────────────────────────────────────────────\n",
      "│ 块 2: 长度=21 字符\n",
      "├──────────────────────────────────────────────────\n",
      "│ ，使开发者能够更容易地构建复杂的应用程序。\n",
      "└──────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T08:46:31.568523Z",
     "start_time": "2025-10-19T08:46:31.545612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入文本分割器\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 2. 定义要分割的文本（含中文标点示例）\n",
    "text = \"这是一个示例文本啊。我们将使用CharacterTextSplitter将其分割成小块。分割基于字符数。\"\n",
    "\n",
    "# 3. 创建文本分割器实例（中文优化配置）\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=30,        # 每个文本块的最大字符数（按Unicode计算）\n",
    "    chunk_overlap=5,      # 块间重叠字符数（避免截断完整词语）\n",
    "    separator=\"。\",       # 优先按中文句号分割（保留语义完整性）\n",
    "    is_separator_regex=False,  # 分隔符不作为正则表达式\n",
    "    keep_separator=True   # 保留分隔符（句号）\n",
    ")\n",
    "\n",
    "# 4. 执行文本分割\n",
    "text_chunks = text_splitter.split_text(text)\n",
    "\n",
    "# 5. 打印分割结果（增强可读性）\n",
    "print(f\"原始文本：\\n「{text}」\\n\")\n",
    "print(f\"总长度：{len(text)} 字符\")\n",
    "print(f\"分割为 {len(text_chunks)} 个文本块：\\n\")\n",
    "\n",
    "for i, chunk in enumerate(text_chunks, start=1):\n",
    "    print(f\"┌{'─' * 40}\")\n",
    "    print(f\"│ 块 {i} (长度: {len(chunk)} 字符)\")\n",
    "    print(f\"├{'─' * 40}\")\n",
    "    print(f\"│ {chunk}\")\n",
    "    print(f\"└{'─' * 40}\\n\")"
   ],
   "id": "3ba498c975d9b5cc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 34, which is longer than the specified 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本：\n",
      "「这是一个示例文本啊。我们将使用CharacterTextSplitter将其分割成小块。分割基于字符数。」\n",
      "\n",
      "总长度：52 字符\n",
      "分割为 3 个文本块：\n",
      "\n",
      "┌────────────────────────────────────────\n",
      "│ 块 1 (长度: 9 字符)\n",
      "├────────────────────────────────────────\n",
      "│ 这是一个示例文本啊\n",
      "└────────────────────────────────────────\n",
      "\n",
      "┌────────────────────────────────────────\n",
      "│ 块 2 (长度: 34 字符)\n",
      "├────────────────────────────────────────\n",
      "│ 。我们将使用CharacterTextSplitter将其分割成小块\n",
      "└────────────────────────────────────────\n",
      "\n",
      "┌────────────────────────────────────────\n",
      "│ 块 3 (长度: 9 字符)\n",
      "├────────────────────────────────────────\n",
      "│ 。分割基于字符数。\n",
      "└────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T08:57:15.489999Z",
     "start_time": "2025-10-19T08:57:15.474742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入文本分割工具\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 2. 定义待分割的中文文本（含句号分隔）\n",
    "text = \"这是第一段文本。这是第二段内容。最后一段结束。\"\n",
    "\n",
    "# 3. 配置中文优化的文本分割器\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"。\",        # 优先按中文句号分割\n",
    "    chunk_size=20,        # 每个文本块最大字符数（含标点）\n",
    "    chunk_overlap=8,      # 块间重叠字符数（保持上下文连贯）\n",
    "    keep_separator=True,  # 保留分隔符（句号）\n",
    "    length_function=len,  # 使用标准Unicode字符计数\n",
    "    is_separator_regex=False  # 分隔符不作为正则表达式\n",
    ")\n",
    "\n",
    "# 4. 执行文本分割\n",
    "text_chunks = text_splitter.split_text(text)\n",
    "\n",
    "# 5. 格式化输出结果\n",
    "print(f\"原始文本：'{text}'\")\n",
    "print(f\"文本总长度：{len(text)} 字符\\n\")\n",
    "print(f\"分割参数：块大小={text_splitter._chunk_size} 重叠={text_splitter._chunk_overlap} 分隔符='{text_splitter._separator}'\\n\")\n",
    "print(f\"共生成 {len(text_chunks)} 个文本块：\")\n",
    "\n",
    "for idx, chunk in enumerate(text_chunks, 1):\n",
    "    chunk = chunk.replace(\"\\n\", \"\\\\n\")  # 转义换行符\n",
    "    print(f\"\\n▌ 块 {idx} (长度: {len(chunk):2d} 字符)\")\n",
    "    print(\"▔\" * (len(chunk) + 10))\n",
    "    print(f\"  {chunk}\")\n",
    "    print(\"▁\" * (len(chunk) + 10))\n",
    "\n",
    "# 打印统计信息\n",
    "print(\"\\n统计摘要：\")\n",
    "print(f\"{'块编号':<8} | {'长度':<6} | {'内容摘要'}\")\n",
    "print(\"-\" * 40)\n",
    "for idx, chunk in enumerate(text_chunks, 1):\n",
    "    print(f\"{idx:<8} | {len(chunk):<6} | {chunk[:15]}...\")"
   ],
   "id": "f7adb321156bd397",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本：'这是第一段文本。这是第二段内容。最后一段结束。'\n",
      "文本总长度：23 字符\n",
      "\n",
      "分割参数：块大小=20 重叠=8 分隔符='。'\n",
      "\n",
      "共生成 2 个文本块：\n",
      "\n",
      "▌ 块 1 (长度: 15 字符)\n",
      "▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔\n",
      "  这是第一段文本。这是第二段内容\n",
      "▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\n",
      "▌ 块 2 (长度: 16 字符)\n",
      "▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔▔\n",
      "  。这是第二段内容。最后一段结束。\n",
      "▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\n",
      "统计摘要：\n",
      "块编号      | 长度     | 内容摘要\n",
      "----------------------------------------\n",
      "1        | 15     | 这是第一段文本。这是第二段内容...\n",
      "2        | 16     | 。这是第二段内容。最后一段结束...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. RecursiveCharacterTextSplitter: 最常用",
   "id": "8df846bdacbf725b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例1: 使用split_text()方法演示",
   "id": "ea8048122b695625"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T11:03:30.099992Z",
     "start_time": "2025-10-19T11:03:30.094977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入递归字符分割器\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 2. 配置递归文本分割器（中英文混合场景优化）\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=10,            # 每个文本块的最大字符数\n",
    "    chunk_overlap=0,          # 块间重叠字符数（0表示不重叠）\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \" \", \"\"],  # 多级分隔符优先级\n",
    "    length_function=len,      # 标准Unicode字符计数\n",
    "    add_start_index=True,     # 记录每个块在原文本的起始位置\n",
    "    keep_separator=True       # 保留分隔符（保持语义完整）\n",
    ")\n",
    "\n",
    "# 3. 定义待分割的混合格式文本\n",
    "text = \"\"\"LangChain框架特性\n",
    "\n",
    "多模型集成(GPT/Claude)\n",
    "记忆管理功能\n",
    "链式调用设计。文档分析场景示例：需要处理PDF/Word等格式。\"\"\"\n",
    "\n",
    "# 4. 执行文本分割\n",
    "paragraphs = text_splitter.split_text(text)\n",
    "\n",
    "for para in paragraphs:\n",
    "    print(para)\n",
    "    print('-'* 10)"
   ],
   "id": "5f0bcdefc1feb09d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain框\n",
      "----------\n",
      "架特性\n",
      "----------\n",
      "多模型集成(GPT\n",
      "----------\n",
      "/Claude)\n",
      "----------\n",
      "记忆管理功能\n",
      "----------\n",
      "链式调用设计\n",
      "----------\n",
      "。文档分析场景示例：\n",
      "----------\n",
      "需要处理PDF/Wo\n",
      "----------\n",
      "rd等格式\n",
      "----------\n",
      "。\n",
      "----------\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例2: 使用create_documents()方法演示,传入字符串列表,返回Document对象列表",
   "id": "badfceb1780145b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T11:05:14.341006Z",
     "start_time": "2025-10-19T11:05:14.330978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入递归字符分割器\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 2. 配置递归文本分割器（中英文混合场景优化）\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=10,            # 每个文本块的最大字符数\n",
    "    chunk_overlap=0,          # 块间重叠字符数（0表示不重叠）\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \" \", \"\"],  # 多级分隔符优先级\n",
    "    length_function=len,      # 标准Unicode字符计数\n",
    "    add_start_index=True,     # 记录每个块在原文本的起始位置\n",
    "    keep_separator=True       # 保留分隔符（保持语义完整）\n",
    ")\n",
    "\n",
    "# 3. 定义待分割的混合格式文本\n",
    "text_list = [\"LangChain框架特性多模型集成(GPT/Claude)记忆管理功能链式调用设计。文档分析场景示例：需要处理PDF/Word等格式。\"]\n",
    "\n",
    "# 4. 执行文本分割\n",
    "paragraphs = text_splitter.create_documents(text_list)\n",
    "\n",
    "for para in paragraphs:\n",
    "    print(para)\n",
    "    print('-'* 10)"
   ],
   "id": "36e26158774dd95d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='LangChain框' metadata={'start_index': 0}\n",
      "----------\n",
      "page_content='架特性多模型集成(G' metadata={'start_index': 10}\n",
      "----------\n",
      "page_content='PT/Claude)' metadata={'start_index': 20}\n",
      "----------\n",
      "page_content='记忆管理功能链式调用' metadata={'start_index': 30}\n",
      "----------\n",
      "page_content='设计' metadata={'start_index': 40}\n",
      "----------\n",
      "page_content='。文档分析场景示例：' metadata={'start_index': 42}\n",
      "----------\n",
      "page_content='需要处理PDF/Wo' metadata={'start_index': 52}\n",
      "----------\n",
      "page_content='rd等格式' metadata={'start_index': 62}\n",
      "----------\n",
      "page_content='。' metadata={'start_index': 67}\n",
      "----------\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例3: 使用create_documents()方法演示,将本地文件内容加载成字符串，进行拆分",
   "id": "76f7a9632495cabb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T11:24:36.013600Z",
     "start_time": "2025-10-19T11:24:35.988411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入相关依赖\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 2. 打开并读取txt文件\n",
    "with open(\"asset/load/08-ai.txt\", encoding=\"utf-8\") as f:\n",
    "    state_of_the_union = f.read()  # 返回字符串\n",
    "\n",
    "# 3. 定义递归字符分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,      # 每个块的最大字符数\n",
    "    chunk_overlap=20,     # 块之间的重叠字符数\n",
    "    length_function=len   # 使用标准长度计算\n",
    ")\n",
    "\n",
    "# 4. 分割文本\n",
    "texts = text_splitter.create_documents([state_of_the_union])\n",
    "\n",
    "# 5. 打印分割结果\n",
    "for text in texts:\n",
    "    print(f\"🔥 {text.page_content}\")\n",
    "    print(\"-\" * 50)  # 分隔线"
   ],
   "id": "eb3f48511513ce27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 人工智能（AI）是什么？\n",
      "--------------------------------------------------\n",
      "🔥 人工智能（Artificial\n",
      "--------------------------------------------------\n",
      "🔥 Intelligence，简称AI）是指由计算机系统模拟人类智能的技术，使其能够执行通常需要人类认知能力的任务，如学习、推理、决策和语言理解。AI的核心目标是让机器具备感知环境、处理信息并自主行动的\n",
      "--------------------------------------------------\n",
      "🔥 让机器具备感知环境、处理信息并自主行动的能力。\n",
      "--------------------------------------------------\n",
      "🔥 1. AI的技术基础\n",
      "AI依赖多种关键技术：\n",
      "\n",
      "机器学习（ML）：通过算法让计算机从数据中学习规律，无需显式编程。例如，推荐系统通过用户历史行为预测偏好。\n",
      "--------------------------------------------------\n",
      "🔥 深度学习：基于神经网络的机器学习分支，擅长处理图像、语音等复杂数据。AlphaGo击败围棋冠军便是典型案例。\n",
      "\n",
      "自然语言处理（NLP）：使计算机理解、生成人类语言，如ChatGPT的对话能力。\n",
      "--------------------------------------------------\n",
      "🔥 2. AI的应用场景\n",
      "AI已渗透到日常生活和各行各业：\n",
      "\n",
      "医疗：辅助诊断（如AI分析医学影像）、药物研发加速。\n",
      "\n",
      "交通：自动驾驶汽车通过传感器和AI算法实现安全导航。\n",
      "--------------------------------------------------\n",
      "🔥 金融：欺诈检测、智能投顾（如风险评估模型）。\n",
      "\n",
      "教育：个性化学习平台根据学生表现调整教学内容。\n",
      "\n",
      "3. AI的挑战与未来\n",
      "尽管前景广阔，AI仍面临问题：\n",
      "--------------------------------------------------\n",
      "🔥 伦理争议：数据隐私、算法偏见（如招聘AI歧视特定群体）。\n",
      "\n",
      "就业影响：自动化可能取代部分人工岗位，但也会创造新职业。\n",
      "\n",
      "技术瓶颈：通用人工智能（AGI）尚未实现，当前AI仅擅长特定任务。\n",
      "--------------------------------------------------\n",
      "🔥 未来，AI将与人类协作而非替代：医生借助AI提高诊断效率，教师利用AI定制课程。其发展需平衡技术创新与社会责任，确保技术造福全人类。\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例4: 使用split_documents()方法演示,利用PDFLoader加载文档,对文档的内容用递归切割器切割",
   "id": "d37ab3f638d66944"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T11:41:56.348480Z",
     "start_time": "2025-10-19T11:41:35.110508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入相关依赖\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 2. 定义PDF加载器\n",
    "loader = PyPDFLoader(\"./asset/load/02-load.pdf\")\n",
    "\n",
    "# 3. 加载PDF文档\n",
    "docs = loader.load()  # 返回Document对象列表\n",
    "\n",
    "# 4. 定义文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,        # 每个块的最大字符数\n",
    "    chunk_overlap=0,       # 块之间的重叠字符数\n",
    "    length_function=len,   # 使用标准长度计算\n",
    "    add_start_index=True   # 记录起始位置\n",
    ")\n",
    "\n",
    "# 5. 分割PDF文档内容\n",
    "paragraphs = text_splitter.split_documents(docs)\n",
    "\n",
    "# 6. 打印分割结果\n",
    "for para in paragraphs:\n",
    "    print(para.page_content)\n",
    "    print(\"-------\")  # 分隔线"
   ],
   "id": "1913957f2fab04e2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\.conda\\envs\\py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"他的车，他的命！ 他忽然想起来，一年，二年，至少有三四年；一滴汗，两滴汗，不\n",
      "知道多少万滴汗，才挣出那辆车。从风里雨里的咬牙，从饭里茶里的自苦，才赚出那辆车。\n",
      "那辆车是他的一切挣扎与困苦的总结果与报酬，像身经百战的武士的一颗徽章。……他老想\n",
      "着远远的一辆车，可以使他自由，独立，像自己的手脚的那么一辆车。\" \n",
      " \n",
      "\"他吃，他喝，他嫖，他赌，他懒，他狡猾， 因为他没了心，他的心被人家摘了去。他\n",
      "-------\n",
      "只剩下那个高大的肉架子，等着溃烂，预备着到乱死岗子去。……体面的、要强的、好梦想\n",
      "的、利己的、个人的、健壮的、伟大的祥子，不知陪着人家送了多少回殡；不知道何时何地\n",
      "会埋起他自己来， 埋起这堕落的、 自私的、 不幸的、 社会病胎里的产儿， 个人主义的末路鬼！\n",
      "\"\n",
      "-------\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. TokenTextSpliter/CharacterTextSpliter\n",
    "\n",
    "\n"
   ],
   "id": "44e36c4546411397"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例1: 使用TokenTextSpliter",
   "id": "118d4d96d4753288"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T12:58:40.174851Z",
     "start_time": "2025-10-19T12:58:36.746471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入相关依赖\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "# 2. 初始化Token文本分割器\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=33,          # 每个块的最大token数\n",
    "    chunk_overlap=0,        # 块之间的重叠token数\n",
    "    encoding_name=\"cl100k_base\"  # 使用OpenAI的编码器\n",
    ")\n",
    "\n",
    "# 3. 定义待分割文本\n",
    "text = \"\"\"人工智能是一个强大的开发框架。它支持多种语言模型和工具链。人工智能是指通过计算机程序\n",
    "模拟人类智能的一门科学。自20世纪50年代诞生以来，人工智能经历了多次起伏。\"\"\"\n",
    "\n",
    "# 4. 执行文本分割\n",
    "text_chunks = text_splitter.split_text(text)\n",
    "\n",
    "# 5. 打印分割结果\n",
    "print(f\"原始文本被分割成了 {len(text_chunks)} 个块:\")\n",
    "for i, chunk in enumerate(text_chunks, 1):\n",
    "    print(f\"\\n▌ 块 {i} (长度: {len(chunk)} 字符)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(chunk)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 打印统计信息\n",
    "print(\"\\n分割统计:\")\n",
    "print(f\"{'块编号':<8} | {'长度':<6} | {'内容摘要'}\")\n",
    "print(\"-\" * 50)\n",
    "for i, chunk in enumerate(text_chunks, 1):\n",
    "    print(f\"{i:<8} | {len(chunk):<6} | {chunk[:20]}...\")"
   ],
   "id": "95b285ed417b52e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本被分割成了 3 个块:\n",
      "\n",
      "▌ 块 1 (长度: 29 字符)\n",
      "--------------------------------------------------\n",
      "人工智能是一个强大的开发框架。它支持多种语言模型和工具链。\n",
      "--------------------------------------------------\n",
      "\n",
      "▌ 块 2 (长度: 31 字符)\n",
      "--------------------------------------------------\n",
      "人工智能是指通过计算机程序\n",
      "模拟人类智能的一门科学。自20世纪\n",
      "--------------------------------------------------\n",
      "\n",
      "▌ 块 3 (长度: 21 字符)\n",
      "--------------------------------------------------\n",
      "50年代诞生以来，人工智能经历了多次起伏。\n",
      "--------------------------------------------------\n",
      "\n",
      "分割统计:\n",
      "块编号      | 长度     | 内容摘要\n",
      "--------------------------------------------------\n",
      "1        | 29     | 人工智能是一个强大的开发框架。它支持多种...\n",
      "2        | 31     | 人工智能是指通过计算机程序\n",
      "模拟人类智能...\n",
      "3        | 21     | 50年代诞生以来，人工智能经历了多次起伏...\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例2: 使用CharacterTextSpliter",
   "id": "914aed527460cc6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T13:04:55.222259Z",
     "start_time": "2025-10-19T13:04:55.195852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入相关依赖\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import tiktoken  # 用于计算Token数量\n",
    "\n",
    "# 2. 定义基于Token的分割器\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",  # 使用OpenAI的编码器\n",
    "    chunk_size=18,                # 每个块的最大Token数\n",
    "    chunk_overlap=0,             # 块之间重叠Token数\n",
    "    separator=\"。\",              # 指定中文句号为分隔符\n",
    "    keep_separator=False         # 不保留分隔符\n",
    ")\n",
    "\n",
    "# 3. 定义待分割文本\n",
    "text = \"\"\"人工智能是一个强大的开发框架。它支持多种语言模型和工具链。今天天气很好，想出去踏青。\n",
    "但是又比较懒不想出去，怎么办\"\"\"\n",
    "\n",
    "# 4. 执行文本分割\n",
    "text_chunks = text_splitter.split_text(text)\n",
    "\n",
    "# 5. 初始化tiktoken编码器（用于Token计数）\n",
    "encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# 6. 打印分割结果\n",
    "print(f\"分割后的块数: {len(text_chunks)}\\n\")\n",
    "\n",
    "for i, chunk in enumerate(text_chunks, 1):\n",
    "    tokens = encoder.encode(chunk)\n",
    "    print(f\"▌ 块 {i} (Token数: {len(tokens)})\")\n",
    "    print(\"-\" * 40)\n",
    "    print(chunk)\n",
    "    print(\"=\" * 40 + \"\\n\")\n",
    "\n",
    "# 打印统计信息\n",
    "print(\"\\n分割统计:\")\n",
    "print(f\"{'块编号':<8} | {'Token数':<8} | {'内容摘要'}\")\n",
    "print(\"-\" * 50)\n",
    "for i, chunk in enumerate(text_chunks, 1):\n",
    "    tokens = encoder.encode(chunk)\n",
    "    print(f\"{i:<8} | {len(tokens):<8} | {chunk[:20]}...\")"
   ],
   "id": "336638c1647334dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后的块数: 4\n",
      "\n",
      "▌ 块 1 (Token数: 17)\n",
      "----------------------------------------\n",
      "人工智能是一个强大的开发框架\n",
      "========================================\n",
      "\n",
      "▌ 块 2 (Token数: 14)\n",
      "----------------------------------------\n",
      "它支持多种语言模型和工具链\n",
      "========================================\n",
      "\n",
      "▌ 块 3 (Token数: 18)\n",
      "----------------------------------------\n",
      "今天天气很好，想出去踏青\n",
      "========================================\n",
      "\n",
      "▌ 块 4 (Token数: 21)\n",
      "----------------------------------------\n",
      "但是又比较懒不想出去，怎么办\n",
      "========================================\n",
      "\n",
      "\n",
      "分割统计:\n",
      "块编号      | Token数   | 内容摘要\n",
      "--------------------------------------------------\n",
      "1        | 17       | 人工智能是一个强大的开发框架...\n",
      "2        | 14       | 它支持多种语言模型和工具链...\n",
      "3        | 18       | 今天天气很好，想出去踏青...\n",
      "4        | 21       | 但是又比较懒不想出去，怎么办...\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. SemanticChunker: 语义分块",
   "id": "a589a21cbe7c5f24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "658ba12e65c82ba5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
