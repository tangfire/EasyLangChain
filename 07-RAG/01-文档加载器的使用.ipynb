{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. 加载Txt文档",
   "id": "7a5b73eb07c985e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T17:03:02.314356Z",
     "start_time": "2025-10-18T17:03:02.299986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, CSVLoader, JSONLoader\n",
    "\n",
    "# 指明txt文档的路径\n",
    "file_path = './asset/load/01-langchain-utf-8.txt'\n",
    "\n",
    "# 创建一个TextLoader的实例\n",
    "text_loader =  TextLoader(\n",
    "    file_path=file_path,\n",
    "    encoding='utf-8',\n",
    ")\n",
    "\n",
    "\n",
    "# 调用load(),返回一个list[Document]\n",
    "docs = text_loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "print(docs[0])\n",
    "\n",
    "print(docs[0].metadata)\n",
    "\n",
    "print(docs[0].page_content)"
   ],
   "id": "a9c458f04d01c910",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "page_content='LangChain 是一个用于构建基于大语言模型（LLM）应用的开发框架，旨在帮助开发者更高效地集成、管理和增强大语言模型的能力，构建端到端的应用程序。它提供了一套模块化工具和接口，支持从简单的文本生成到复杂的多步骤推理任务' metadata={'source': './asset/load/01-langchain-utf-8.txt'}\n",
      "{'source': './asset/load/01-langchain-utf-8.txt'}\n",
      "LangChain 是一个用于构建基于大语言模型（LLM）应用的开发框架，旨在帮助开发者更高效地集成、管理和增强大语言模型的能力，构建端到端的应用程序。它提供了一套模块化工具和接口，支持从简单的文本生成到复杂的多步骤推理任务\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T17:04:46.863988Z",
     "start_time": "2025-10-18T17:04:46.858968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 指明txt文档的路径\n",
    "file_path = './asset/load/01-langchain-gbk.txt'\n",
    "\n",
    "# 创建一个TextLoader的实例\n",
    "text_loader =  TextLoader(\n",
    "    file_path=file_path,\n",
    "    encoding='gbk', # 此时使用的解码集一定要与当初存储文件使用的编码集相同，否则报错\n",
    ")\n",
    "\n",
    "\n",
    "# 调用load(),返回一个list[Document]\n",
    "docs = text_loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "print(docs[0])\n",
    "\n",
    "print(docs[0].metadata)\n",
    "\n",
    "print(docs[0].page_content)"
   ],
   "id": "c1496323d2108476",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "page_content='LangChain 是一个用于构建基于大语言模型（LLM）应用的开发框架，旨在帮助开发者更高效地集成、管理和增强大语言模型的能力，构建端到端的应用程序。它提供了一套模块化工具和接口，支持从简单的文本生成到复杂的多步骤推理任务' metadata={'source': './asset/load/01-langchain-gbk.txt'}\n",
      "{'source': './asset/load/01-langchain-gbk.txt'}\n",
      "LangChain 是一个用于构建基于大语言模型（LLM）应用的开发框架，旨在帮助开发者更高效地集成、管理和增强大语言模型的能力，构建端到端的应用程序。它提供了一套模块化工具和接口，支持从简单的文本生成到复杂的多步骤推理任务\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. 加载pdf",
   "id": "71ef2aab755ef5fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```bash\n",
    "pip install pypdf\n",
    "```"
   ],
   "id": "17d3ad0558033516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T17:09:31.817447Z",
     "start_time": "2025-10-18T17:09:31.799247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community. document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(\n",
    "    file_path=\"./asset/load/02-load.pdf\",\n",
    ")\n",
    "\n",
    "docs = pdf_loader.load()\n",
    "\n",
    "print(docs)\n",
    "\n"
   ],
   "id": "e445c77397b77971",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-06-20T17:18:19+08:00', 'moddate': '2025-06-20T17:18:19+08:00', 'source': './asset/load/02-load.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='\"他的车，他的命！ 他忽然想起来，一年，二年，至少有三四年；一滴汗，两滴汗，不\\n知道多少万滴汗，才挣出那辆车。从风里雨里的咬牙，从饭里茶里的自苦，才赚出那辆车。\\n那辆车是他的一切挣扎与困苦的总结果与报酬，像身经百战的武士的一颗徽章。……他老想\\n着远远的一辆车，可以使他自由，独立，像自己的手脚的那么一辆车。\" \\n \\n\"他吃，他喝，他嫖，他赌，他懒，他狡猾， 因为他没了心，他的心被人家摘了去。他\\n只剩下那个高大的肉架子，等着溃烂，预备着到乱死岗子去。……体面的、要强的、好梦想\\n的、利己的、个人的、健壮的、伟大的祥子，不知陪着人家送了多少回殡；不知道何时何地\\n会埋起他自己来， 埋起这堕落的、 自私的、 不幸的、 社会病胎里的产儿， 个人主义的末路鬼！\\n\"')]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "也可以加载网络中的一个文件",
   "id": "2d0893ed28b8ddb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T17:20:16.550901Z",
     "start_time": "2025-10-18T17:20:15.485979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community. document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(\n",
    "    file_path=\"https://arxiv.org/pdf/2302.03803\",\n",
    ")\n",
    "\n",
    "docs = pdf_loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "\n"
   ],
   "id": "58f46cc7a9691055",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. 加载CSV文档",
   "id": "9f6853636d6e7b63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T17:22:25.776798Z",
     "start_time": "2025-10-18T17:22:25.767226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from  langchain_community. document_loaders. csv_loader import CSVLoader\n",
    "\n",
    "csv_loader = CSVLoader(file_path=\"./asset/load/03-load.csv\",)\n",
    "\n",
    "docs = csv_loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ],
   "id": "777ddede2c8906ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "page_content='id: 1\n",
      "title: Introduction to Python\n",
      "content: Python is a popular programming language.\n",
      "author: John Doe' metadata={'source': './asset/load/03-load.csv', 'row': 0}\n",
      "page_content='id: 2\n",
      "title: Data Science Basics\n",
      "content: Data science involves statistics and machine learning.\n",
      "author: Jane Smith' metadata={'source': './asset/load/03-load.csv', 'row': 1}\n",
      "page_content='id: 3\n",
      "title: Web Development\n",
      "content: HTML, CSS and JavaScript are core web technologies.\n",
      "author: Mike Johnson' metadata={'source': './asset/load/03-load.csv', 'row': 2}\n",
      "page_content='id: 4\n",
      "title: Artificial Intelligence\n",
      "content: AI is transforming many industries.\n",
      "author: Sarah Williams' metadata={'source': './asset/load/03-load.csv', 'row': 3}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T17:23:33.984338Z",
     "start_time": "2025-10-18T17:23:33.965346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from  langchain_community. document_loaders. csv_loader import CSVLoader\n",
    "\n",
    "csv_loader = CSVLoader(file_path=\"./asset/load/03-load.csv\",source_column=\"author\")\n",
    "\n",
    "docs = csv_loader.load()\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ],
   "id": "84dd7c9a378417ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='id: 1\n",
      "title: Introduction to Python\n",
      "content: Python is a popular programming language.\n",
      "author: John Doe' metadata={'source': 'John Doe', 'row': 0}\n",
      "page_content='id: 2\n",
      "title: Data Science Basics\n",
      "content: Data science involves statistics and machine learning.\n",
      "author: Jane Smith' metadata={'source': 'Jane Smith', 'row': 1}\n",
      "page_content='id: 3\n",
      "title: Web Development\n",
      "content: HTML, CSS and JavaScript are core web technologies.\n",
      "author: Mike Johnson' metadata={'source': 'Mike Johnson', 'row': 2}\n",
      "page_content='id: 4\n",
      "title: Artificial Intelligence\n",
      "content: AI is transforming many industries.\n",
      "author: Sarah Williams' metadata={'source': 'Sarah Williams', 'row': 3}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. 加载JSON文档",
   "id": "8986d489da74b861"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. 举例1: 加载json文件中的所有的数据",
   "id": "90835533f0344c3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T05:15:55.068969Z",
     "start_time": "2025-10-19T05:15:55.051079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community. document_loaders. json_loader import JSONLoader\n",
    "\n",
    "json_loader =  JSONLoader(\n",
    "    file_path=\"./asset/load/04-load.json\",\n",
    "    jq_schema=\".\",  # 表示加载所有的字段\n",
    "    text_content=False # 将加载的json对象转换为json字符串\n",
    ")\n",
    "\n",
    "docs = json_loader.load()\n",
    "\n",
    "print(docs)"
   ],
   "id": "1bc73e7dd5dbf32c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'D:\\\\GitRespority04\\\\EasyLangChain\\\\07-RAG\\\\asset\\\\load\\\\04-load.json', 'seq_num': 1}, page_content='{\"messages\": [{\"sender\": \"Alice\", \"content\": \"Hello, how are you today?\", \"timestamp\": \"2023-05-15T10:00:00\"}, {\"sender\": \"Bob\", \"content\": \"I\\'m doing well, thanks for asking!\", \"timestamp\": \"2023-05-15T10:02:00\"}, {\"sender\": \"Alice\", \"content\": \"Would you like to meet for lunch?\", \"timestamp\": \"2023-05-15T10:05:00\"}, {\"sender\": \"Bob\", \"content\": \"Sure, that sounds great!\", \"timestamp\": \"2023-05-15T10:07:00\"}], \"conversation_id\": \"conv_12345\", \"participants\": [\"Alice\", \"Bob\"]}')]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例2: 加载json文件中messages[]中的所有content字段",
   "id": "4f88e9b1b781cd43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T05:37:41.278770Z",
     "start_time": "2025-10-19T05:37:41.266739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community. document_loaders. json_loader import JSONLoader\n",
    "\n",
    "json_loader =  JSONLoader(\n",
    "    file_path=\"./asset/load/04-load.json\",\n",
    "    jq_schema=\".messages[].content\",  # 表示加载所有的字段\n",
    "    # text_content=False # 将加载的json对象转换为json字符串\n",
    ")\n",
    "\n",
    "docs = json_loader.load()\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ],
   "id": "b29e85fdfc6db7f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you today?\n",
      "I'm doing well, thanks for asking!\n",
      "Would you like to meet for lunch?\n",
      "Sure, that sounds great!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例3: 提取04-resource.json文件中嵌套在data.items[].content的文本",
   "id": "b31ada54cec2aae5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T05:42:35.736640Z",
     "start_time": "2025-10-19T05:42:35.711652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community. document_loaders. json_loader import JSONLoader\n",
    "\n",
    "# 方式1:\n",
    "# json_loader =  JSONLoader(\n",
    "#     file_path=\"./asset/load/04-response.json\",\n",
    "#     jq_schema=\".data.items[].content\",  \n",
    "#     # text_content=False # 将加载的json对象转换为json字符串\n",
    "# )\n",
    "\n",
    "# 方式2:\n",
    "json_loader =  JSONLoader(\n",
    "    file_path=\"./asset/load/04-response.json\",\n",
    "    jq_schema=\".data.items[]\",  \n",
    "    # text_content=False, # 将加载的json对象转换为json字符串\n",
    "    content_key=\".content\",\n",
    "    is_content_key_jq_parsable=True\n",
    ")\n",
    "\n",
    "\n",
    "docs = json_loader.load()\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ],
   "id": "a6d8fc1d720618cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article explains how to parse API responses...\n",
      "Learn to handle nested structures with...\n",
      "Best practices for preserving metadata...\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例4:",
   "id": "821a681ff1d9a9ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T05:50:05.787366Z",
     "start_time": "2025-10-19T05:50:05.764165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community. document_loaders. json_loader import JSONLoader\n",
    "\n",
    "# 方式1:\n",
    "# json_loader =  JSONLoader(\n",
    "#     file_path=\"./asset/load/04-response.json\",\n",
    "#     jq_schema=\".data.items[].content\",  \n",
    "#     # text_content=False # 将加载的json对象转换为json字符串\n",
    "# )\n",
    "\n",
    "# 方式2:\n",
    "json_loader =  JSONLoader(\n",
    "    file_path=\"./asset/load/04-response.json\",\n",
    "    jq_schema=\".data.items[]\",  \n",
    "    # text_content=False, # 将加载的json对象转换为json字符串\n",
    "    content_key='.title + \"\\\\n\\\\n\" + .content',\n",
    "    is_content_key_jq_parsable=True\n",
    ")\n",
    "\n",
    "\n",
    "docs = json_loader.load()\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ],
   "id": "340912e1ef2dc4da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding JSONLoader\n",
      "\n",
      "This article explains how to parse API responses...\n",
      "Advanced jq Schema Patterns\n",
      "\n",
      "Learn to handle nested structures with...\n",
      "LangChain Metadata Handling\n",
      "\n",
      "Best practices for preserving metadata...\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. 加载HTML(了解)",
   "id": "ce0f415045079ef4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```bash\n",
    "pip install unstructured\n",
    "```"
   ],
   "id": "6b23d53513ae175c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T06:06:36.043188Z",
     "start_time": "2025-10-19T06:06:35.985747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# 下载基本资源 - 确保使用正确的资源名称\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')  # 注意：不是 'averaged_perceptron_tagger_eng'\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "# 获取 NLTK 数据目录\n",
    "nltk_data_dir = nltk.data.path[0]\n",
    "taggers_dir = Path(nltk_data_dir) / 'taggers'\n",
    "\n",
    "# 确保目录存在\n",
    "taggers_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 源目录和目标目录\n",
    "src_dir = taggers_dir / 'averaged_perceptron_tagger'\n",
    "dst_dir = taggers_dir / 'averaged_perceptron_tagger_eng'\n",
    "\n",
    "# 方法1：如果源目录存在但目标不存在，复制目录\n",
    "if src_dir.exists() and not dst_dir.exists():\n",
    "    shutil.copytree(src_dir, dst_dir)\n",
    "    print(f\"已复制目录: {src_dir} -> {dst_dir}\")\n",
    "\n",
    "# 方法2：如果源目录不存在，尝试直接下载所需资源\n",
    "elif not src_dir.exists():\n",
    "    try:\n",
    "        # 尝试直接下载所需资源\n",
    "        nltk.download('averaged_perceptron_tagger_eng')\n",
    "        print(\"已直接下载 'averaged_perceptron_tagger_eng'\")\n",
    "    except:\n",
    "        # 如果失败，尝试使用备用名称\n",
    "        try:\n",
    "            nltk.download('averaged_perceptron_tagger')\n",
    "            if not dst_dir.exists():\n",
    "                shutil.copytree(src_dir, dst_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"无法下载所需资源: {e}\")\n",
    "            # 使用BeautifulSoup作为备选方案\n",
    "            from langchain.document_loaders import BSHTMLLoader\n",
    "            loader = BSHTMLLoader(\"asset/load/05-load.html\")\n",
    "            docs = loader.load()\n",
    "            # 继续处理docs..."
   ],
   "id": "b58f2ffc14fc6698",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T06:14:00.576304Z",
     "start_time": "2025-10-19T06:13:58.867352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 导入依赖\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "\n",
    "# 2. 创建加载器实例\n",
    "html_loader = UnstructuredHTMLLoader(\n",
    "    file_path=\"asset/load/05-load.html\",  # HTML文件路径\n",
    "    mode=\"elements\",                      # 分割模式：按语义元素拆分\n",
    "    strategy=\"fast\"                       # 解析策略：快速模式（速度优先）\n",
    ")\n",
    "\n",
    "# 3. 加载并分割文档\n",
    "docs = html_loader.load()\n",
    "\n",
    "# 4. 打印分割结果\n",
    "print(f\"共分割出 {len(docs)} 个元素\")\n",
    "for doc in docs:\n",
    "    print(\"---- 元素内容 ----\")\n",
    "    print(doc)\n",
    "    print(\"\\n\")"
   ],
   "id": "8a7f511b67daf4bb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已直接下载 'averaged_perceptron_tagger_eng'\n",
      "共分割出 16 个元素\n",
      "---- 元素内容 ----\n",
      "page_content='首发于自然语言处理算法与实践' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['zho'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'category': 'UncategorizedText', 'element_id': 'b082a3e1f4714ffa5f25741f39d82c17'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='RAG:将检索与生成方式相结合来做生成任务' metadata={'source': 'asset/load/05-load.html', 'category_depth': 0, 'last_modified': '2025-09-23T17:01:27', 'languages': ['kor'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'category': 'Title', 'element_id': '46103fd31eae47ed36481d13185af8a9'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='烛之文' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['kor'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '46103fd31eae47ed36481d13185af8a9', 'category': 'UncategorizedText', 'element_id': 'e02798c2e2bb964165a9e9356b82a3f6'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='1、前言' metadata={'source': 'asset/load/05-load.html', 'category_depth': 1, 'last_modified': '2025-09-23T17:01:27', 'languages': ['zho'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '46103fd31eae47ed36481d13185af8a9', 'category': 'Title', 'element_id': '683a24e897e3a9b862ead6c7979a58dc'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='在上一篇<kNN-NER：利用knn近邻算法来做命名实体识别>提及到文中提出kNN-NER框架是一种检索式增强的方法（retrieval augmented methods），就去查看有关retrieval augmented的paper，了解其核心思想，觉得检索式增强的方法很适合许多业务场景使用，因其以一种简捷的方式将外部知识融于模型中去。今天就分享一篇来自Facebook AI Research的paper<Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks>，论文提出一种检索式增强生成方法，应用于知识密集型的NLP任务（如问答生成），该篇论文被2020年NeurIPS 会议接收。' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['nor'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '683a24e897e3a9b862ead6c7979a58dc', 'category': 'NarrativeText', 'element_id': 'd345b4a58c84984eb1acf1105fd9f214'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='文中说到，以BERT之类的大规模预训练模型将很多事实知识信息存入模型中，可以看着是pre-trained parametric类型，尽管以fine-tuned方式在下游任务取得显著的成效，但这类方法仍存在无法精准地获取和操作知识的缺陷。而在上述提及的问题上，传统知识检索的方法能很好的应对，这类方法可以看着是non-parametric memory类型。于是，论文提出检索式增强生成方法（retrieval-augmented generation，RAG），主要思想就是将pre-trained parametric与non-parametric memory结合起来做语言生成任务，将两类模型集成起来提高任务处理效果。' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['nor'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '683a24e897e3a9b862ead6c7979a58dc', 'category': 'UncategorizedText', 'element_id': '2fe8d146b5803ec72e5173bf15599710'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='2、RAG方法' metadata={'source': 'asset/load/05-load.html', 'category_depth': 1, 'last_modified': '2025-09-23T17:01:27', 'languages': ['zho'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '46103fd31eae47ed36481d13185af8a9', 'category': 'Title', 'element_id': '22ca96c9bf71395b8fbbf0928bd7f292'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='上图为论文提出RAG模型的整体示意图。主要包括两大模块：一个检索器（Retriever， p_\\\\eta(z|x) ） + 一个生成器（Generator， p_\\\\theta(y_i|x,z,y_{1:i-1}) ）。前者包括query encoder和document index，分别负责query的编码和文档的索引；后者是一个seq2seq的生成模型。在检索中，使用的是最大内积搜索的方法（MIPS）来检索top-K相关文档。' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['cat', 'nor'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '22ca96c9bf71395b8fbbf0928bd7f292', 'category': 'NarrativeText', 'element_id': '6bbc63aaa7b3afb8d2685e9b3de78a4c'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='3、实验' metadata={'source': 'asset/load/05-load.html', 'category_depth': 1, 'last_modified': '2025-09-23T17:01:27', 'languages': ['zho'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '46103fd31eae47ed36481d13185af8a9', 'category': 'Title', 'element_id': '4df308cd6991fb9e3f0592371bae26be'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='论文在四类Knowledge-Intensive 任务上进行实验，具体包括开放问答（Open-domain Question Answering ）、摘要式问答（Abstractive Question Answering） 、开放问题生成（Jeopardy Question Generation）、事实判断（Fact Verification ），并使用维基百科（包含2100万个文档）作为检索库。' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '4df308cd6991fb9e3f0592371bae26be', 'category': 'UncategorizedText', 'element_id': 'ed6e043c7fd99ec0824b91725c66e0ba'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='4、结语' metadata={'source': 'asset/load/05-load.html', 'category_depth': 1, 'last_modified': '2025-09-23T17:01:27', 'languages': ['zho'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '46103fd31eae47ed36481d13185af8a9', 'category': 'Title', 'element_id': '95bc5bffaa5cfd41f5242f9f8b330761'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='本次分享基于检索增强方式将外部知识融于生成任务中一个新的框架――RAG。对比T5 和 BART这类擅长处理生成任务的模型来说，RAG更新外部知识是不需要重新预训练，成本低；而对比pipeline方法，RAG利用外部知识并不需要构造负责的特征工程。总的来说，RAG方法可作为外部知识融合框架的一种有效实例。' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['zho', 'kor'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '95bc5bffaa5cfd41f5242f9f8b330761', 'category': 'UncategorizedText', 'element_id': '232dc4ae399e0a8847bfcdeb2e64e215'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='有兴趣可关注笔者公众号：自然语言处理算法与实践' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['zho', 'kor'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '95bc5bffaa5cfd41f5242f9f8b330761', 'category': 'UncategorizedText', 'element_id': '41f28a1034fdc4291daf652054c20bd2'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='编辑于 2022-04-06 10:47' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['zho'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '95bc5bffaa5cfd41f5242f9f8b330761', 'category': 'UncategorizedText', 'element_id': 'f70255f8bf13d39885508fd845c22382'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='深度学习（Deep Learning）' metadata={'source': 'asset/load/05-load.html', 'last_modified': '2025-09-23T17:01:27', 'languages': ['nld', 'eng'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '95bc5bffaa5cfd41f5242f9f8b330761', 'category': 'UncategorizedText', 'element_id': '1818d3e8e3a4ce395732bba3428a111d'}\n",
      "\n",
      "\n",
      "---- 元素内容 ----\n",
      "page_content='自然语言处理算法与实践' metadata={'source': 'asset/load/05-load.html', 'category_depth': 2, 'last_modified': '2025-09-23T17:01:27', 'languages': ['kor', 'zho'], 'file_directory': 'asset/load', 'filename': '05-load.html', 'filetype': 'text/html', 'parent_id': '95bc5bffaa5cfd41f5242f9f8b330761', 'category': 'Title', 'element_id': '95058f2148219d97462c5c4bfe175502'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. 加载Markdown(了解)",
   "id": "488fad92ee1807ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```bash\n",
    "pip install markdown\n",
    "\n",
    "pip install unstructured\n",
    "```"
   ],
   "id": "dea55741d22be101"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T06:16:01.185430Z",
     "start_time": "2025-10-19T06:16:01.152589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关的依赖\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from pprint import pprint\n",
    "# 2.定义UnstructuredMarkdownLoader对象\n",
    "md_loader = UnstructuredMarkdownLoader(\n",
    "    file_path=\"asset/load/06-load.md\",\n",
    "    strategy=\"fast\"\n",
    ")\n",
    "# 3.加载\n",
    "docs = md_loader.load()\n",
    "print(len(docs))\n",
    "# 4.打印\n",
    "for doc in docs:\n",
    "    print(doc)"
   ],
   "id": "d56095080a0b04fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "page_content='自然语言处理技术文档\n",
      "\n",
      "本文档用于测试UnstructuredMarkdownLoader的中文处理能力。\n",
      "\n",
      "第一章：简介\n",
      "\n",
      "自然语言处理(NLP)是人工智能的重要分支，主要技术包括：\n",
      "\n",
      "文本分类\n",
      "\n",
      "命名实体识别\n",
      "\n",
      "机器翻译\n",
      "\n",
      "情感分析\n",
      "\n",
      "问答系统\n",
      "\n",
      "第二章：关键技术\n",
      "\n",
      "2.1 预训练模型\n",
      "\n",
      "BERT：双向Transformer编码器\n",
      "\n",
      "GPT：自回归语言模型\n",
      "\n",
      "T5：文本到文本转换框架\n",
      "\n",
      "2.2 代码示例\n",
      "\n",
      "```python from transformers import pipeline\n",
      "\n",
      "创建文本分类管道\n",
      "\n",
      "classifier = pipeline(\"text-classification\", model=\"bert-base-chinese\")\n",
      "\n",
      "result = classifier(\"这家餐厅的服务很棒！\") print(result)' metadata={'source': 'asset/load/06-load.md'}\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T06:19:49.382658Z",
     "start_time": "2025-10-19T06:19:49.345750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关的依赖\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from pprint import pprint\n",
    "# 2.定义UnstructuredMarkdownLoader对象\n",
    "md_loader = UnstructuredMarkdownLoader(\n",
    "    file_path=\"asset/load/06-load.md\",\n",
    "    strategy=\"fast\",\n",
    "    mode=\"elements\",\n",
    ")\n",
    "# 3.加载\n",
    "docs = md_loader.load()\n",
    "print(len(docs))\n",
    "# 4.打印\n",
    "for doc in docs:\n",
    "    print(doc)"
   ],
   "id": "a9c62270ace66c79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "page_content='自然语言处理技术文档' metadata={'source': 'asset/load/06-load.md', 'category_depth': 0, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'category': 'Title', 'element_id': '184afae73069130590c7608c471f63f4'}\n",
      "page_content='本文档用于测试UnstructuredMarkdownLoader的中文处理能力。' metadata={'source': 'asset/load/06-load.md', 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '184afae73069130590c7608c471f63f4', 'category': 'UncategorizedText', 'element_id': '18f55c7a014f88171f86dc848b58a83b'}\n",
      "page_content='第一章：简介' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '184afae73069130590c7608c471f63f4', 'category': 'Title', 'element_id': '6a6844d806798af924a74eecc9bf3c1f'}\n",
      "page_content='自然语言处理(NLP)是人工智能的重要分支，主要技术包括：' metadata={'source': 'asset/load/06-load.md', 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '6a6844d806798af924a74eecc9bf3c1f', 'category': 'UncategorizedText', 'element_id': 'e7b3e94da2b42ec341e42747172c2fb1'}\n",
      "page_content='文本分类' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '6a6844d806798af924a74eecc9bf3c1f', 'category': 'ListItem', 'element_id': 'eb53d308db7e96fa7bf107143411c209'}\n",
      "page_content='命名实体识别' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '6a6844d806798af924a74eecc9bf3c1f', 'category': 'ListItem', 'element_id': 'd3cd19f3de6c7be342b6d45249ed5936'}\n",
      "page_content='机器翻译' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '6a6844d806798af924a74eecc9bf3c1f', 'category': 'ListItem', 'element_id': '4af0dd9da13771840a9696cdcbb502e1'}\n",
      "page_content='情感分析' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '6a6844d806798af924a74eecc9bf3c1f', 'category': 'ListItem', 'element_id': '862050b1daeb945947f4c00587f16954'}\n",
      "page_content='问答系统' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '6a6844d806798af924a74eecc9bf3c1f', 'category': 'ListItem', 'element_id': '7f221beeb60cc8089f9878c70230b9a5'}\n",
      "page_content='第二章：关键技术' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '184afae73069130590c7608c471f63f4', 'category': 'Title', 'element_id': 'c2bf8c7c4e88556b7afb7b5407d4fbf2'}\n",
      "page_content='2.1 预训练模型' metadata={'source': 'asset/load/06-load.md', 'category_depth': 2, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': 'c2bf8c7c4e88556b7afb7b5407d4fbf2', 'category': 'Title', 'element_id': 'd32a685b6777cb3277c7732ca2603203'}\n",
      "page_content='BERT：双向Transformer编码器' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'emphasized_text_contents': ['BERT'], 'emphasized_text_tags': ['b'], 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': 'd32a685b6777cb3277c7732ca2603203', 'category': 'ListItem', 'element_id': '3efd83a33d46349a06c9489309f23af0'}\n",
      "page_content='GPT：自回归语言模型' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'emphasized_text_contents': ['GPT'], 'emphasized_text_tags': ['b'], 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': 'd32a685b6777cb3277c7732ca2603203', 'category': 'ListItem', 'element_id': '042b24863d1db56d10e6222413089a30'}\n",
      "page_content='T5：文本到文本转换框架' metadata={'source': 'asset/load/06-load.md', 'category_depth': 1, 'emphasized_text_contents': ['T5'], 'emphasized_text_tags': ['b'], 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': 'd32a685b6777cb3277c7732ca2603203', 'category': 'ListItem', 'element_id': '7da9d82f5274c3edb7ae917995c08db2'}\n",
      "page_content='2.2 代码示例' metadata={'source': 'asset/load/06-load.md', 'category_depth': 2, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': 'c2bf8c7c4e88556b7afb7b5407d4fbf2', 'category': 'Title', 'element_id': '58fa664fefbefa6e86ee4fc8dd128878'}\n",
      "page_content='```python from transformers import pipeline' metadata={'source': 'asset/load/06-load.md', 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': '58fa664fefbefa6e86ee4fc8dd128878', 'category': 'NarrativeText', 'element_id': '2d72807f991457ffe38dad8b46480b0b'}\n",
      "page_content='创建文本分类管道' metadata={'source': 'asset/load/06-load.md', 'category_depth': 0, 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'category': 'Title', 'element_id': 'f5a25376ceb9e9392b4e0b2b60153cca'}\n",
      "page_content='classifier = pipeline(\"text-classification\", model=\"bert-base-chinese\")' metadata={'source': 'asset/load/06-load.md', 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': 'f5a25376ceb9e9392b4e0b2b60153cca', 'category': 'UncategorizedText', 'element_id': '9745c5d59a60933121ca91a9b71e6acf'}\n",
      "page_content='result = classifier(\"这家餐厅的服务很棒！\") print(result)' metadata={'source': 'asset/load/06-load.md', 'languages': ['eng'], 'file_directory': 'asset/load', 'filename': '06-load.md', 'filetype': 'text/markdown', 'last_modified': '2025-09-23T17:01:26', 'parent_id': 'f5a25376ceb9e9392b4e0b2b60153cca', 'category': 'UncategorizedText', 'element_id': '7ebd846af465424c8c01cb58cfa79c86'}\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. 加载File Directory(了解)",
   "id": "98a72e4f1fe233bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```bash\n",
    "pip install unstructured\n",
    "```"
   ],
   "id": "6b8d08267f46a571"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T06:21:01.967765Z",
     "start_time": "2025-10-19T06:21:01.865490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关的依赖\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PythonLoader\n",
    "from pprint import pprint\n",
    "# 2.定义DirectoryLoader对象,指定要加载的文件夹路径、要加载的文件类型和是否使用多线程\n",
    "directory_loader = DirectoryLoader(\n",
    "    path=\"./asset/load\",\n",
    "    glob=\"*.py\",\n",
    "    use_multithreading=True,\n",
    "    show_progress=True,\n",
    "    loader_cls=PythonLoader\n",
    ")\n",
    "# 3.加载\n",
    "docs = directory_loader.load()\n",
    "# 4.打印\n",
    "print(len(docs))\n",
    "for doc in docs:\n",
    "    pprint(doc)"
   ],
   "id": "295a02a5c16d6512",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 312.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Document(metadata={'source': 'asset\\\\load\\\\07-param_form.py'}, page_content='\"\"\"\\n三 函数参数形式\\n\"\"\"\\n# 1.位置参数\\n# 2.关键字参数\\n# 3.默认参数\\n# 4.不定长参数\\n# 4.1 带一个*\\ndef printInfo(num,*vartuple):\\n    print(num)\\n    print(vartuple)\\n\\nprintInfo(70,60,50)\\n\\nprint(\"-\" * 20)\\n# 如果不定长的参数后面还有参数,必须通过关键字参数传参\\ndef printInfo1(num1,*vartuple,num) :\\n    print(num)\\n    print(num1)\\n    print(vartuple)\\n\\nprintInfo1(10,20,num = 40)\\n\\nprint(\"-\" * 20)\\n# 如果没有给不定长的参数传参,那么得到的是空元组\\nprintInfo1(70,num = 60)\\n# 4.2 带二个*\\ndef printInfo(num,**vardict):\\n    print(num)\\n    print(vardict)\\n    # return\\n\\nprintInfo(10,key1 = 20,key2 = 30)')\n",
      "Document(metadata={'source': 'asset\\\\load\\\\07-fun.py'}, page_content='\"\"\"\\n一 函数入门\\n\"\"\"\\n# 1.不使用函数\\n# 打印欢迎信息1\\nprint(\"********************************\")\\nprint(\"*                              *\")\\nprint(\"*     欢迎来到Python世界       *\")\\nprint(\"*                              *\")\\nprint(\"********************************\")\\n\\n# 打印欢迎信息2\\nprint(\"********************************\")\\nprint(\"*                              *\")\\nprint(\"*     欢迎来到Python世界       *\")\\nprint(\"*                              *\")\\nprint(\"********************************\")\\n\\n# 打印欢迎信息3\\nprint(\"********************************\")\\nprint(\"*                              *\")\\nprint(\"*     欢迎来到Python世界       *\")\\nprint(\"*                              *\")\\nprint(\"********************************\")\\n\\n# 2.使用函数\\ndef print_welcome():\\n    \"\"\"打印欢迎信息\"\"\"\\n    print(\"********************************\")\\n    print(\"*                              *\")\\n    print(\"*     欢迎来到Python世界       *\")\\n    print(\"*                              *\")\\n    print(\"********************************\")\\n\\n# 多次调用函数打印欢迎信息\\nprint_welcome()\\nprint_welcome()\\nprint_welcome()')\n",
      "Document(metadata={'source': 'asset\\\\load\\\\07-fun_param.py'}, page_content='\"\"\"\\n二 函数参数\\n\"\"\"\\n\\n\\n# 1. 无参数版本 - 只能计算固定的购物车\\ndef calculate_total_no_params():\\n    \"\"\"计算固定购物车总价\"\"\"\\n    prices = [100, 50, 30]  # 商品价格固定写死在函数内\\n    total = 0\\n    for price in prices:\\n        total += price\\n    return total\\n\\n# 只能计算一个固定的购物车\\nprint(f\"购物车总价:{calculate_total_no_params()}\")\\n\\n# 2.有参数版本 - 可以计算任意购物车\\ndef calculate_total(prices):\\n    \"\"\"计算任意购物车总价\"\"\"\\n    total = 0\\n    for price in prices:\\n        total += price\\n    return total\\n\\n# 可以计算任意购物车\\ncart1 = [100, 50, 30]\\ncart2 = [200, 80, 45, 60]\\ncart3 = [75, 90, 120]\\n\\nprint(\"第一个购物车总价:{calculate_total(cart1)}:\")\\nprint(\"第二个购物车总价:{calculate_total(cart2)}\")\\nprint(f\"第三个购物车总价:{calculate_total(cart3)}\")\\n\\n\\n# 3.参数传递\\n# 3.1 不可变类型 函数传递不可变对象\\n\\ndef changeInt(a) :\\n    print(\"函数体中未改变前a的内存地址\",id(a))\\n    a = 10   #底层会创建一个新对象 然后给新对象一个新值\\n    print(\"函数体中改变后a的内存地址\",id(a))\\n\\na = 2 # 创建一个对象 然后给这个对象一个值\\nchangeInt(a)\\nprint(a)\\nprint(\"函数外b的内存地址\",id(a))\\n\\n\\n\\n# 输出结果\\n# 函数体中未改变前a的内存地址 140729722661336\\n# 函数体中改变后a的内存地址 140729722661592\\n# 2\\n# 函数外b的内存地址 140729722661336\\n\\n\\n# 3.2 可变类型 函数传递不可变对象\\n\\ndef changeList(myList) :\\n    myList[1] = 50\\n    print(\"函数内的值\",myList) # [1,50,3]\\n    print(\"函数内列表的内存\",id(myList)) # 0111111\\n\\nmlist = [1,2,3]  # 底层创建一个对象 地址0111111\\nchangeList(mlist)\\nprint(\"函数外的值\",mlist) # # [1,50,3]\\nprint(\"函数外列表的内存\",id(mlist))\\n\\n# 输出结果\\n# 函数内的值 [1, 50, 3]\\n# 函数内列表的内存 1380193079680\\n# 函数外的值 [1, 50, 3]\\n# 函数外列表的内存 1380193079680\\n\\n')\n",
      "Document(metadata={'source': 'asset\\\\load\\\\07-fun_retun.py'}, page_content='\"\"\"\\n四 函数的返回值\\n\"\"\"\\n# 1.返回表达式\\n# 2.不带表达式的 return 语句，返回 None。\\n# 3.函数中如果没有 return 语句，在函数运行结束后也会返回 None。\\n# 4.用变量接收返回结果\\n# 5.return 语句可以返回多个值，多个值会放在一个元组中。\\n\\ndef f(a, b, c):\\n    return a, b, c, [a, b, c]\\nprint(f(1, 2, 3))  # (1, 2, 3, [1, 2, 3])\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
