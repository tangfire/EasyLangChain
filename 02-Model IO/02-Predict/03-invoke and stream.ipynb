{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在 LangChain 中，`Runnable` 是构建复杂处理链的基础接口。任何实现了 `Runnable` 接口的对象都拥有一套标准化的调用方法，这使得不同的组件可以无缝连接和组合。\n",
    "\n",
    "以下是 `Runnable` 定义的公共调用方法：\n",
    "\n",
    "---\n",
    "\n",
    "### 核心调用方法\n",
    "\n",
    "#### 1. `invoke(input: Any, config: Optional[RunnableConfig] = None) -> Any`\n",
    "**作用**：**同步调用**单条输入数据，并返回单条输出结果。\n",
    "**参数**：\n",
    "- `input`：单条输入数据，类型取决于具体的 Runnable（如字符串、Message、字典等）。\n",
    "- `config`（可选）：运行时配置，可包含调用参数、回调、并发配置等。\n",
    "**返回**：单条输出结果。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# 创建一个简单的 Runnable\n",
    "runnable = RunnableLambda(lambda x: x.upper())\n",
    "\n",
    "# 同步调用单条输入\n",
    "result = runnable.invoke(\"hello\")\n",
    "print(result)  # 输出: \"HELLO\"\n",
    "```\n",
    "\n",
    "#### 2. `batch(inputs: List[Any], config: Optional[RunnableConfig] = None, *, return_exceptions: bool = False) -> List[Any]`\n",
    "**作用**：**同步批量处理**多条输入数据，返回多条输出结果。\n",
    "**参数**：\n",
    "- `inputs`：输入数据列表。\n",
    "- `config`（可选）：运行时配置。\n",
    "- `return_exceptions`（默认为 False）：如果为 True，处理过程中遇到的异常会作为结果返回；如果为 False，遇到异常会直接抛出。\n",
    "**返回**：输出结果列表。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "results = runnable.batch([\"hello\", \"world\", \"langchain\"])\n",
    "print(results)  # 输出: [\"HELLO\", \"WORLD\", \"LANGCHAIN\"]\n",
    "```\n",
    "\n",
    "#### 3. `stream(input: Any, config: Optional[RunnableConfig] = None) -> Iterator[Any]`\n",
    "**作用**：**同步流式处理**单条输入数据，以迭代器形式逐步返回输出片段。\n",
    "**参数**：\n",
    "- `input`：单条输入数据。\n",
    "- `config`（可选）：运行时配置。\n",
    "**返回**：输出结果的迭代器。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "for chunk in runnable.stream(\"hello\"):\n",
    "    print(chunk)  # 逐步输出: \"H\", \"E\", \"L\", \"L\", \"O\"\n",
    "```\n",
    "\n",
    "#### 4. `astream(input: Any, config: Optional[RunnableConfig] = None) -> AsyncIterator[Any]`\n",
    "**作用**：**异步流式处理**单条输入数据，以异步迭代器形式逐步返回输出片段。\n",
    "**参数**：\n",
    "- `input`：单条输入数据。\n",
    "- `config`（可选）：运行时配置。\n",
    "**返回**：异步迭代器。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "async for chunk in runnable.astream(\"hello\"):\n",
    "    print(chunk)  # 逐步输出\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 异步调用方法\n",
    "\n",
    "#### 5. `ainvoke(input: Any, config: Optional[RunnableConfig] = None) -> Any`\n",
    "**作用**：**异步调用**单条输入数据，返回单条输出结果。\n",
    "**参数**：\n",
    "- `input`：单条输入数据。\n",
    "- `config`（可选）：运行时配置。\n",
    "**返回**：单条输出结果的 Awaitable。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "result = await runnable.ainvoke(\"hello\")\n",
    "print(result)  # 输出: \"HELLO\"\n",
    "```\n",
    "\n",
    "#### 6. `abatch(inputs: List[Any], config: Optional[RunnableConfig] = None, *, return_exceptions: bool = False) -> List[Any]`\n",
    "**作用**：**异步批量处理**多条输入数据，返回多条输出结果。\n",
    "**参数**：\n",
    "- `inputs`：输入数据列表。\n",
    "- `config`（可选）：运行时配置。\n",
    "- `return_exceptions`：是否返回异常。\n",
    "**返回**：输出结果列表的 Awaitable。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "results = await runnable.abatch([\"hello\", \"world\"])\n",
    "print(results)  # 输出: [\"HELLO\", \"WORLD\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 配置相关方法\n",
    "\n",
    "#### 7. `with_config(config: Optional[RunnableConfig] = None, **kwargs) -> Runnable`\n",
    "**作用**：为 Runnable 添加默认配置。\n",
    "**参数**：\n",
    "- `config`：配置对象。\n",
    "- `**kwargs`：也可以直接传递配置键值对。\n",
    "**返回**：配置后的新 Runnable 实例。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "configured_runnable = runnable.with_config(tags=[\"prod\"], max_concurrency=5)\n",
    "```\n",
    "\n",
    "#### 8. `with_listeners(on_start: Optional[Listener] = None, on_end: Optional[Listener] = None, on_error: Optional[Listener] = None) -> Runnable`\n",
    "**作用**：添加执行监听器。\n",
    "**参数**：\n",
    "- `on_start`：开始执行时的回调。\n",
    "- `on_end`：执行结束时的回调。\n",
    "- `on_error`：执行出错时的回调。\n",
    "**返回**：带有监听器的新 Runnable 实例。\n",
    "\n",
    "---\n",
    "\n",
    "### 组合方法\n",
    "\n",
    "#### 9. `pipe(next: Runnable) -> RunnableSequence`\n",
    "**作用**：将当前 Runnable 与另一个 Runnable 连接起来，形成处理链。\n",
    "**参数**：\n",
    "- `next`：下一个要连接的 Runnable。\n",
    "**返回**：RunnableSequence 序列。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: x.upper())\n",
    "runnable2 = RunnableLambda(lambda x: x + \"!\")\n",
    "\n",
    "chain = runnable1.pipe(runnable2)\n",
    "result = chain.invoke(\"hello\")\n",
    "print(result)  # 输出: \"HELLO!\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 其他实用方法\n",
    "\n",
    "#### 10. `map() -> RunnableMap`\n",
    "**作用**：创建多个 Runnable 的并行映射。\n",
    "\n",
    "#### 11. `transform() -> RunnableTransform`\n",
    "**作用**：对输入流进行转换。\n",
    "\n",
    "---\n",
    "\n",
    "### RunnableConfig 配置内容\n",
    "\n",
    "`RunnableConfig` 可以包含以下配置项：\n",
    "\n",
    "- `tags`: List[str] - 执行的标签\n",
    "- `metadata`: Dict[str, Any] - 元数据\n",
    "- `callbacks`: CallbackManager - 回调管理器\n",
    "- `max_concurrency`: Optional[int] - 最大并发数\n",
    "- `run_name`: Optional[str] - 运行名称\n",
    "- `configurable`: Dict[str, Any] - 可配置参数\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "from langchain_core.callbacks import ConsoleCallbackHandler\n",
    "\n",
    "config = {\n",
    "    \"tags\": [\"test-run\"],\n",
    "    \"callbacks\": [ConsoleCallbackHandler()]\n",
    "}\n",
    "\n",
    "result = runnable.invoke(\"hello\", config=config)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 总结表格\n",
    "\n",
    "| 方法 | 作用 | 同步/异步 | 输入类型 | 输出类型 |\n",
    "|------|------|-----------|----------|----------|\n",
    "| `invoke` | 单条同步调用 | 同步 | 单条数据 | 单条结果 |\n",
    "| `batch` | 批量同步调用 | 同步 | 数据列表 | 结果列表 |\n",
    "| `stream` | 同步流式调用 | 同步 | 单条数据 | 迭代器 |\n",
    "| `astream` | 异步流式调用 | 异步 | 单条数据 | 异步迭代器 |\n",
    "| `ainvoke` | 单条异步调用 | 异步 | 单条数据 | 单条结果 |\n",
    "| `abatch` | 批量异步调用 | 异步 | 数据列表 | 结果列表 |\n",
    "\n",
    "这些标准化的方法使得 LangChain 中的各种组件（LLM、工具、链、代理等）能够以统一的方式进行交互和组合，构成了 LangChain 强大而灵活的处理能力。"
   ],
   "id": "435e5bc3c4ee7159"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例1: invoke()阻塞式的调用",
   "id": "37edc0116e9c37d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T05:35:38.469987Z",
     "start_time": "2025-09-21T05:35:35.474049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=os.getenv(\"MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"BASE_URL\"),\n",
    ")\n",
    "\n",
    "message = [HumanMessage(content=\"你好，请介绍一下自己\")]\n",
    "\n",
    "response = chat_model.invoke(message)\n",
    "\n",
    "print(response.content)"
   ],
   "id": "735ccae9c1a372",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我叫豆包，是由字节跳动研发的人工智能。我就像一个知识渊博的伙伴，拥有丰富的知识储备，能为你解答各种各样的问题，无论是历史典故、科学原理、生活常识，还是文学艺术、技术应用等领域。\n",
      "\n",
      "我可以陪你聊天，听你分享日常趣事、烦恼忧愁；能帮你撰写文案，如故事、诗歌、报告等；还能进行文本翻译、代码编写、逻辑推理等。只要你有需求，随时都能和我交流，我会尽力为你提供准确、有用的信息和贴心的服务。 \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2: 流式的演示",
   "id": "a75f14bce9274730"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T05:51:20.365211Z",
     "start_time": "2025-09-21T05:51:17.335232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=os.getenv(\"MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"BASE_URL\"),\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "message = [HumanMessage(content=\"你好，请介绍一下自己\")]\n",
    "\n",
    "print(\"开始流式输出: \")\n",
    "for chunk in chat_model.stream(message):\n",
    "    # 刷新缓冲区(无换行符，缓冲区未刷新，内容可能不会立即显示)\n",
    "    print(chunk.content,end=\"\",flush=True)\n",
    "print(\"\\n流式输出结束\")"
   ],
   "id": "516f8fbc4f0690ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始流式输出: \n",
      "我叫豆包，是由字节跳动研发的人工智能。我拥有丰富的知识储备，能为你解答各种各样的问题，涵盖历史、科学、技术、文化、生活等诸多领域。\n",
      "\n",
      "我可以陪你聊天，倾听你的想法和感受，为你排忧解难；能帮你撰写文章，像故事、诗歌、论文、文案等都不在话下；进行文本润色、翻译；还能提供旅游攻略、美食推荐、学习方法建议等实用信息。\n",
      "\n",
      "无论何时，只要你有需求，都能随时和我交流，我会尽力为你提供准确且有价值的回应。 \n",
      "流式输出结束\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "举例3: 批量调用\n",
    "\n"
   ],
   "id": "8820d1c56dec6eb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T06:18:38.593887Z",
     "start_time": "2025-09-21T06:18:21.035476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=os.getenv(\"MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"BASE_URL\"),\n",
    ")\n",
    "\n",
    "message1 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),HumanMessage(content=\"请帮我介绍一下什么是机器学习\"),]\n",
    "\n",
    "message2 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),HumanMessage(content=\"请帮我介绍一下什么是AIGC\"),]\n",
    "\n",
    "message3 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),HumanMessage(content=\"请帮我介绍一下什么是大模型技术\"),]\n",
    "\n",
    "message = [message1,message2,message3]\n",
    "\n",
    "response = chat_model.batch(message)\n",
    "\n",
    "print(response)"
   ],
   "id": "f3c9d81b90ba7d29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='机器学习是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。它专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。以下从几个方面详细介绍：\\n\\n### 机器学习的基本概念\\n- **学习过程**：本质上是一个从数据中寻找模式和规律的过程。例如，在一个包含大量手写数字图像及其对应数字标签的数据集中，机器学习算法会尝试找出图像像素特征与数字标签之间的关联模式。\\n- **自我完善**：随着数据的不断输入和学习的持续进行，模型会自动调整自身的参数和结构，以提高对未知数据的预测准确性或执行特定任务的能力。比如语音识别系统，随着用户使用次数增多，识别准确率会不断提升。\\n\\n### 机器学习的主要任务类型\\n- **监督学习**\\n    - 定义：数据集中每个样本都有对应的标签，算法的目标是学习输入数据和标签之间的映射关系，以便对新的输入数据进行预测。\\n    - 举例：垃圾邮件分类，将邮件的文本内容作为输入，标签为“垃圾邮件”或“正常邮件”，通过学习大量的邮件数据，算法就能判断新邮件是否为垃圾邮件。\\n- **无监督学习**\\n    - 定义：数据集中没有标签，算法需要自行发现数据中的结构和模式。\\n    - 举例：在客户细分中，根据客户的购买行为、消费习惯等数据，将客户划分成不同的群体，每个群体内的客户具有相似的特征。\\n- **强化学习**\\n    - 定义：智能体（agent）在环境中进行一系列的动作，通过与环境交互获得奖励或惩罚信号，目标是学习到一个最优的策略，使得长期累积奖励最大化。\\n    - 举例：训练机器人下棋，机器人每走一步都会得到相应的反馈（奖励或惩罚），通过不断尝试和学习，找到能赢得比赛的最佳策略。\\n\\n### 机器学习的应用领域\\n- **图像识别**：广泛应用于人脸识别、安防监控、医学影像诊断等领域。例如，人脸识别技术可用于门禁系统，提高安全性和便捷性。\\n- **自然语言处理**：包括机器翻译、智能客服、语音助手等。像谷歌翻译能够实现多种语言之间的实时翻译。\\n- **金融领域**：用于风险评估、信用评分、股票价格预测等。银行可以通过分析客户的信用历史、收入情况等数据，评估贷款风险。\\n- **医疗保健**：辅助疾病诊断、药物研发、医疗影像分析等。例如，通过分析患者的基因数据和临床信息，为个性化医疗提供支持。\\n\\n### 机器学习的基本流程\\n- **数据收集**：收集与任务相关的大量数据，数据的质量和数量对模型的性能有重要影响。\\n- **数据预处理**：对收集到的数据进行清洗、特征提取、特征选择等操作，以提高数据的质量和可用性。\\n- **模型选择与训练**：根据任务的特点选择合适的机器学习算法，并使用预处理后的数据对模型进行训练。\\n- **模型评估**：使用测试数据对训练好的模型进行评估，常用的评估指标包括准确率、召回率、均方误差等。\\n- **模型部署与优化**：将评估合格的模型部署到实际应用中，并根据实际使用情况对模型进行持续优化。 ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 749, 'prompt_tokens': 28, 'total_tokens': 777, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'doubao-1-5-pro-32k-250115', 'system_fingerprint': None, 'id': '021758435501520df2623e15c2929d95288060e426177a2f14ebf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--baa9d32f-92ab-4e3e-b125-66b811829888-0', usage_metadata={'input_tokens': 28, 'output_tokens': 749, 'total_tokens': 777, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), AIMessage(content='AIGC即人工智能生成内容（AI-Generated Content），是指利用人工智能技术来生成内容的一系列技术和应用。它被认为是继专业生产内容（PGC）、用户生产内容（UGC）之后的新型内容创作方式。以下从多个方面为你详细介绍：\\n\\n### 核心技术\\nAIGC主要基于深度学习等人工智能技术，常见的有生成对抗网络（GAN）、变分自编码器（VAE）和大型语言模型（LLM）等。\\n- **生成对抗网络**：包含生成器和判别器两个部分。生成器负责生成数据，判别器则判断数据是真实的还是生成的。两者通过不断对抗和博弈，提升生成器生成数据的质量，常用于图像生成、视频生成等领域。\\n- **变分自编码器**：是一种生成模型，它可以学习数据的潜在分布，并从中采样生成新的数据。在图像生成、数据压缩等方面有广泛应用。\\n- **大型语言模型**：基于Transformer架构，通过在大规模文本数据上进行无监督学习，学习语言的模式和规律。能够理解和生成自然语言文本，可用于文本生成、问答系统、机器翻译等。\\n\\n### 应用领域\\n- **文本创作**：能够撰写新闻稿、小说、诗歌、广告文案、代码等。例如，记者可以利用AIGC快速生成简单的新闻报道初稿，程序员可以借助它辅助编写代码和查找代码中的问题。\\n- **图像生成**：根据用户输入的文本描述生成相应的图像。设计师可以利用这些工具快速生成设计草图，减少前期构思和绘制的时间。\\n- **音频生成**：可以生成语音、音乐等。有声书制作公司可以利用语音合成技术将文字内容转换为语音，音乐创作者也可以借助AIGC生成音乐素材，获取创作灵感。\\n- **视频生成**：自动生成视频内容，包括动画、影视片段等。可以用于制作简单的宣传视频、动画短片等，降低视频制作的门槛和成本。\\n\\n### 优势\\n- **提高创作效率**：能够在短时间内生成大量的内容，大大节省了人力和时间成本。比如，一篇需要人类作者花费数小时才能完成的文案，AIGC可能在几分钟内就能生成。\\n- **激发创新灵感**：可以为创作者提供新的思路和创意方向。例如，在艺术创作中，AIGC生成的独特图像或音乐可能会启发艺术家创造出更具创新性的作品。\\n- **个性化创作**：根据用户的个性化需求生成定制化的内容。例如，根据用户的兴趣爱好和浏览历史，为用户生成个性化的新闻推荐、广告内容等。\\n\\n### 挑战和问题\\n- **内容质量问题**：生成的内容可能存在逻辑错误、事实不准确等问题，需要人工进行审核和修正。\\n- **版权归属问题**：AIGC生成内容的版权归属尚不明确，引发了一系列法律和道德争议。\\n- **伦理和社会影响**：可能被用于虚假信息传播、深度伪造等不良行为，对社会秩序和安全造成威胁。 ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 668, 'prompt_tokens': 30, 'total_tokens': 698, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'doubao-1-5-pro-32k-250115', 'system_fingerprint': None, 'id': '02175843550152120362fc7e6079c27e4aa871382f590dd95528e', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c1a2ac8e-0c4b-4b95-9f01-39c5d7a3132b-0', usage_metadata={'input_tokens': 30, 'output_tokens': 668, 'total_tokens': 698, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), AIMessage(content='大模型技术是近年来人工智能领域的一项关键技术，以下从定义、特点、训练过程、应用领域等方面为你详细介绍：\\n\\n### 定义\\n大模型技术通常指的是具有海量参数的人工智能模型。这些模型基于深度学习架构，如Transformer架构，通过在大规模数据集上进行训练，学习到数据中的复杂模式和规律，从而具备强大的语言理解、生成、推理等多种能力。例如，GPT - 3有1750亿个参数，它能够处理各种自然语言任务。\\n\\n### 特点\\n- **参数规模庞大**：大模型包含大量的参数，参数数量可达数十亿、数百亿甚至更多。大量的参数使得模型能够学习到更加复杂和细致的模式，从而在各种任务中表现出更好的性能。\\n- **强大的泛化能力**：经过大规模数据的训练，大模型能够学习到通用的知识和模式，从而在不同的任务和领域中都能有较好的表现。它可以处理多种类型的自然语言处理任务，如文本生成、问答系统、机器翻译等。\\n- **涌现能力**：当模型的参数规模、数据量达到一定程度时，会出现一些在小规模模型中没有的能力，如复杂推理、常识理解等，这种现象被称为涌现能力。\\n\\n### 训练过程\\n- **数据收集**：收集大量的文本数据，这些数据来源广泛，包括互联网上的各种文本、书籍、新闻、论文等。数据的多样性和规模对于模型的性能至关重要。\\n- **数据预处理**：对收集到的数据进行清洗、标注、分词等预处理操作，以提高数据的质量和可用性。\\n- **模型架构选择**：选择合适的深度学习架构，如Transformer，它具有强大的并行计算能力和长序列处理能力，非常适合处理自然语言任务。\\n- **训练优化**：使用大规模的计算资源，如GPU集群或TPU，对模型进行训练。训练过程中使用优化算法，如随机梯度下降（SGD）及其变种，不断调整模型的参数，以最小化损失函数。\\n\\n### 应用领域\\n- **自然语言处理**：包括文本生成（如写作文章、故事、诗歌等）、机器翻译、问答系统、智能客服、信息抽取等。\\n- **图像和视频处理**：大模型可以用于图像生成、图像识别、视频内容理解和生成等。例如，DALL - E 2能够根据文本描述生成高质量的图像。\\n- **医疗保健**：辅助疾病诊断、医学影像分析、药物研发等。通过分析大量的医疗数据和病例，大模型可以为医生提供决策支持。\\n- **金融服务**：风险评估、信贷分析、投资决策、市场趋势预测等。大模型可以处理和分析海量的金融数据，挖掘其中的潜在规律和风险。 \\n\\n### 挑战与局限\\n- **计算资源需求大**：训练大模型需要消耗大量的计算资源和能源，成本高昂。\\n- **数据隐私和安全**：使用大规模数据进行训练可能涉及到数据隐私和安全问题，需要采取有效的措施来保护用户数据。\\n- **可解释性差**：大模型通常是一个“黑盒”，其决策过程难以解释，这在一些对可解释性要求较高的领域，如医疗和法律，可能会受到限制。 ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 718, 'prompt_tokens': 30, 'total_tokens': 748, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'doubao-1-5-pro-32k-250115', 'system_fingerprint': None, 'id': '021758435501521fc13e928c98afebfb2c224739f41e786fba4f1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f91d01c4-5a3f-4473-aa6a-33bc965def21-0', usage_metadata={'input_tokens': 30, 'output_tokens': 718, 'total_tokens': 748, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
