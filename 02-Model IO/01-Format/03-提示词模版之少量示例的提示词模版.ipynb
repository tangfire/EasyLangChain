{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 少量示例的提示词模版的使用\n",
    "FewShotPromptTemplate: 与PromptTemplate一起使用(非对话式)\n",
    "FewShotChatMessagePromptTemplate: 与ChatPromptTemplate一起使用(对话式)\n",
    "Example selectors(示例选择器):"
   ],
   "id": "1c127feae0404dc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. FewShotPromptTemplate的使用",
   "id": "288e036b36b84f82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例1: 未提供示例的情况:",
   "id": "f2a727821bb83123"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:20:26.898558Z",
     "start_time": "2025-09-21T16:20:23.121462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from sys import prefix\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# 调用非对话模型:\n",
    "# llms = OpenAI(...)\n",
    "\n",
    "dotenv.load_dotenv() # 加载当前目录下的.env文件\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "\n",
    "\n",
    "# 调用对话模型:\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name=os.environ['MODEL'],\n",
    "    base_url=os.environ['BASE_URL'],\n",
    "    api_key=os.environ['ARK_API_KEY']\n",
    ")\n",
    "\n",
    "response =   chat_model.invoke(\"2 @@@ 9 是多少?\")\n",
    "\n",
    "print(response.content)\n",
    "\n"
   ],
   "id": "d103d862f13775de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "仅“2 @@@ 9”这样的表述，由于“@@@”不是常见的数学运算符号，不清楚其具体代表的运算规则，所以无法计算出结果。\n",
      "\n",
      "你可以给我解释一下“@@@”所代表的运算含义，这样我就能为你准确计算了。 \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2: 使用FewShotPromptTemplate",
   "id": "720bc022172e9b1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:35:53.341028Z",
     "start_time": "2025-09-21T16:35:53.228565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate, ChatPromptTemplate, \\\n",
    "    FewShotChatMessagePromptTemplate\n",
    "\n",
    "example_prompt =  PromptTemplate.from_template(\n",
    "    template=\"input:{input}\\noutput:{output}\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"北京天气怎么样?\",\"output\":\"北京市\"},\n",
    "    {\"input\":\"南京下雨吗?\",\"output\":\"南京市\"},\n",
    "    {\"input\":\"武汉热吗?\",\"output\":\"武汉市\"}\n",
    "]\n",
    "\n",
    "few_shot_template =  FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"input:{input}\\noutput:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "few_shot_template.invoke({\"input\":\"天津会下雨吗？\"})"
   ],
   "id": "ae3506f20f697121",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='input:北京天气怎么样?\\noutput:北京市\\n\\ninput:南京下雨吗?\\noutput:南京市\\n\\ninput:武汉热吗?\\noutput:武汉市\\n\\ninput:天津会下雨吗？\\noutput:')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "调用大模型以后:",
   "id": "e581a0951859e21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:39:11.225017Z",
     "start_time": "2025-09-21T16:39:10.354638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "\n",
    "# 调用非对话模型:\n",
    "# llms = OpenAI(...)\n",
    "\n",
    "dotenv.load_dotenv() # 加载当前目录下的.env文件\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "\n",
    "\n",
    "# 调用对话模型:\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name=os.environ['MODEL'],\n",
    "    base_url=os.environ['BASE_URL'],\n",
    "    api_key=os.environ['ARK_API_KEY']\n",
    ")\n",
    "\n",
    "example_prompt =  PromptTemplate.from_template(\n",
    "    template=\"input:{input}\\noutput:{output}\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"北京天气怎么样?\",\"output\":\"北京市\"},\n",
    "    {\"input\":\"南京下雨吗?\",\"output\":\"南京市\"},\n",
    "    {\"input\":\"武汉热吗?\",\"output\":\"武汉市\"}\n",
    "]\n",
    "\n",
    "few_shot_template =  FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"input:{input}\\noutput:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "few_shot_prompt =  few_shot_template.invoke({\"input\":\"天津会下雨吗？\"})\n",
    "\n",
    "response =  chat_model.invoke(few_shot_prompt)\n",
    "print(response.content)\n",
    "\n"
   ],
   "id": "1ac174e17d0cab11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天津市\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 示例2:",
   "id": "a44565d33945780"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:41:43.105769Z",
     "start_time": "2025-09-21T16:41:42.269779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 调用非对话模型:\n",
    "# llms = OpenAI(...)\n",
    "\n",
    "dotenv.load_dotenv() # 加载当前目录下的.env文件\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "\n",
    "\n",
    "# 调用对话模型:\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name=os.environ['MODEL'],\n",
    "    base_url=os.environ['BASE_URL'],\n",
    "    api_key=os.environ['ARK_API_KEY']\n",
    ")\n",
    "\n",
    "\n",
    "example_prompt =  PromptTemplate.from_template(\n",
    "    template=\"input:{input}\\noutput:{output}\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"3 @@@ 3 是多少?\",\"output\":\"0\"},\n",
    "    {\"input\":\"4 @@@ 2 是多少?\",\"output\":\"2\"},\n",
    "    {\"input\":\"2 @@@ 4 是多少?\",\"output\":\"-2\"}\n",
    "]\n",
    "\n",
    "few_shot_template =  FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"input:{input}\\noutput:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "few_shot_prompt =  few_shot_template.invoke({\"input\":\"2 @@@ 9是多少?\"})\n",
    "\n",
    "response =   chat_model.invoke(few_shot_prompt)\n",
    "\n",
    "print(response.content)\n",
    "\n"
   ],
   "id": "b044b134228c963a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 示例3:",
   "id": "f1e7278cd1c96e52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:47:46.520734Z",
     "start_time": "2025-09-21T16:47:45.498630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 调用非对话模型:\n",
    "# llms = OpenAI(...)\n",
    "\n",
    "dotenv.load_dotenv() # 加载当前目录下的.env文件\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "\n",
    "\n",
    "# 调用对话模型:\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name=os.environ['MODEL'],\n",
    "    base_url=os.environ['BASE_URL'],\n",
    "    api_key=os.environ['ARK_API_KEY']\n",
    ")\n",
    "\n",
    "\n",
    "example_prompt =  PromptTemplate.from_template(\n",
    "    template=\"你是一个数学专家,算式: {input} 值: {output} 使用: {description}\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"2 + 2\",\"output\":\"4\",\"description\":\"加法运算\"},\n",
    "    {\"input\":\"5 - 2\",\"output\":\"3\",\"description\":\"减法运算\"},\n",
    "]\n",
    "\n",
    "few_shot_template =  FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"你是一个数学专家,算式: {input}, 值: {output}\",\n",
    "    input_variables=[\"input\",\"output\"],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "response =   chat_model.invoke(few_shot_template.invoke({\"input\":\"2 * 5\",\"output\":\"10\"}))\n",
    "\n",
    "print(response.content)\n",
    "\n"
   ],
   "id": "b8db692a17123280",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用: 乘法运算\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. FewShotChatMessagePromptTemplate的使用",
   "id": "80d5a43e67bc0828"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例1: 实例化",
   "id": "87084dde6b0163e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:08:09.252303Z",
     "start_time": "2025-09-22T12:08:09.236347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain. prompts import (ChatPromptTemplate,FewShotChatMessagePromptTemplate)\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"1+1=?\",\"output\":\"1+1=2\"},\n",
    "    {\"input\":\"法国的首都是?\",\"output\":\"巴黎\"}\n",
    "]\n",
    "\n",
    "msg_example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\",\"{input}\"),\n",
    "    (\"ai\",\"{output}\"),\n",
    "])\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=msg_example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ],
   "id": "946c99d395f526ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 1+1=?\n",
      "AI: 1+1=2\n",
      "Human: 法国的首都是?\n",
      "AI: 巴黎\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2:",
   "id": "e8669117d3de478b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:22:20.841932Z",
     "start_time": "2025-09-22T12:22:17.209735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain. prompts import (ChatPromptTemplate,FewShotChatMessagePromptTemplate)\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"2 @@@ 2\",\"output\":\"4\"},\n",
    "    {\"input\":\"2 @@@ 3\",\"output\":\"8\"}\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\",\"{input} 是多少?\"),\n",
    "    (\"ai\",\"{output}\"),\n",
    "])\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=msg_example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"你是一个数学奇才\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\",\"{input}\")\n",
    "])\n",
    "\n",
    "dotenv.load_dotenv() # 加载当前目录下的.env文件\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "\n",
    "\n",
    "# 调用对话模型:\n",
    "chat_model =  ChatOpenAI(\n",
    "    model_name=os.environ['MODEL'],\n",
    "    base_url=os.environ['BASE_URL'],\n",
    "    api_key=os.environ['ARK_API_KEY']\n",
    ")\n",
    "\n",
    "resp =  chat_model.invoke(final_prompt.invoke(input=\"2 @@@ 4\"))\n",
    "\n",
    "print(resp.content)\n"
   ],
   "id": "fe31621ff47cc68c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "\n",
      "从前面的“2 @@@ 2 = 4”（\\(2^2 = 4\\)），“2 @@@ 3 = 8”（\\(2^3 = 8\\)）可以推测出“@@@”运算的规律是：\\(a @@@ b=a^b\\)。\n",
      "\n",
      "那么当\\(a = 2\\)，\\(b = 4\\)时，\\(2 @@@ 4=2^4 = 16\\)。 \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Example selectors(示例选择器)",
   "id": "75ad59384994a94a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例1:",
   "id": "46369607c7299a05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:14:37.609377Z",
     "start_time": "2025-09-22T13:14:37.567931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import dotenv\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "dotenv.load_dotenv() # 加载当前目录下的.env文件\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "os.environ[\"MODEL_EMBEDDING\"] = os.getenv(\"MODEL_EMBEDDING\")\n",
    "\n",
    "\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=os.environ['MODEL_EMBEDDING'],\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"苹果公司总部在哪里？\",\n",
    "        \"answer\": \"苹果公司总部位于美国加利福尼亚州的库比蒂诺。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"水果苹果有什么营养价值？\",\n",
    "        \"answer\": \"苹果富含维生素、膳食纤维和抗氧化物质，有助于消化和健康。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"如何购买iPhone？\",\n",
    "        \"answer\": \"可以通过苹果官网、授权零售商或电信运营商购买iPhone。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"怎样种植苹果树？\",\n",
    "        \"answer\": \"种植苹果树需要选择合适的品种、土壤和气候条件，定期修剪和施肥。\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"苹果手机的最新型号是什么？\",\n",
    "        \"answer\": \"请查看苹果官方网站获取最新iPhone型号信息，产品线会定期更新。\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(examples,embeddings_model,Chroma,k=1)\n",
    "\n",
    "question = \"安卓手机的最新型号是什么?\"\n",
    "selected_examples = example_selector({\"question\":question})\n",
    "\n",
    "print(f\"与输入最相似的示例:{selected_examples}\")\n",
    "\n"
   ],
   "id": "e75870898b659258",
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOpenAIError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 18\u001B[0m\n\u001B[0;32m     13\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBASE_URL\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBASE_URL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     14\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMODEL_EMBEDDING\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMODEL_EMBEDDING\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 18\u001B[0m embeddings_model \u001B[38;5;241m=\u001B[39m \u001B[43mOpenAIEmbeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMODEL_EMBEDDING\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m examples \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     24\u001B[0m     {\n\u001B[0;32m     25\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m苹果公司总部在哪里？\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     43\u001B[0m     }\n\u001B[0;32m     44\u001B[0m ]\n\u001B[0;32m     46\u001B[0m example_selector \u001B[38;5;241m=\u001B[39m SemanticSimilarityExampleSelector\u001B[38;5;241m.\u001B[39mfrom_examples(examples,embeddings_model,Chroma,k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310\\lib\\site-packages\\langchain_openai\\embeddings\\base.py:328\u001B[0m, in \u001B[0;36mOpenAIEmbeddings.validate_environment\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    326\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_client \u001B[38;5;241m=\u001B[39m httpx\u001B[38;5;241m.\u001B[39mClient(proxy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopenai_proxy)\n\u001B[0;32m    327\u001B[0m     sync_specific \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp_client\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_client}\n\u001B[1;32m--> 328\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient \u001B[38;5;241m=\u001B[39m openai\u001B[38;5;241m.\u001B[39mOpenAI(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mclient_params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msync_specific)\u001B[38;5;241m.\u001B[39membeddings  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masync_client:\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopenai_proxy \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_async_client:\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310\\lib\\site-packages\\openai\\_client.py:135\u001B[0m, in \u001B[0;36mOpenAI.__init__\u001B[1;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001B[0m\n\u001B[0;32m    133\u001B[0m     api_key \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m api_key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 135\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OpenAIError(\n\u001B[0;32m    136\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    137\u001B[0m     )\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(api_key):\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mOpenAIError\u001B[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2:",
   "id": "45eb41e3958fc045"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:13:51.713806Z",
     "start_time": "2025-09-22T13:13:51.670528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain. prompts import (ChatPromptTemplate,FewShotChatMessagePromptTemplate)\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "dotenv.load_dotenv() # 加载当前目录下的.env文件\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = os.getenv(\"ARK_API_KEY\")\n",
    "os.environ[\"MODEL\"] = os.getenv(\"MODEL\")\n",
    "os.environ[\"BASE_URL\"] = os.getenv(\"BASE_URL\")\n",
    "os.environ[\"MODEL_EMBEDDING\"] = os.getenv(\"MODEL_EMBEDDING\")\n",
    "\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=os.environ['MODEL_EMBEDDING'],\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    # 形容词正反义\n",
    "    {\n",
    "        \"input\": \"高兴\",\n",
    "        \"output\": \"悲伤\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"美丽\",\n",
    "        \"output\": \"丑陋\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"富有\",\n",
    "        \"output\": \"贫穷\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"聪明\",\n",
    "        \"output\": \"愚蠢\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"强大\",\n",
    "        \"output\": \"弱小\"\n",
    "    },\n",
    "    \n",
    "    # 动词正反义\n",
    "    {\n",
    "        \"input\": \"爱\",\n",
    "        \"output\": \"恨\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"建设\",\n",
    "        \"output\": \"破坏\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"增加\",\n",
    "        \"output\": \"减少\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"接受\",\n",
    "        \"output\": \"拒绝\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"开始\",\n",
    "        \"output\": \"结束\"\n",
    "    },\n",
    "    \n",
    "    # 名词正反义\n",
    "    {\n",
    "        \"input\": \"朋友\",\n",
    "        \"output\": \"敌人\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"成功\",\n",
    "        \"output\": \"失败\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"希望\",\n",
    "        \"output\": \"绝望\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"优点\",\n",
    "        \"output\": \"缺点\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"白天\",\n",
    "        \"output\": \"夜晚\"\n",
    "    },\n",
    "    \n",
    "    # 程度副词正反义\n",
    "    {\n",
    "        \"input\": \"总是\",\n",
    "        \"output\": \"从不\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"全部\",\n",
    "        \"output\": \"没有\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"经常\",\n",
    "        \"output\": \"很少\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"很快\",\n",
    "        \"output\": \"很慢\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"很多\",\n",
    "        \"output\": \"很少\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(examples,embeddings_model,FAISS,k=2)\n",
    "\n",
    "similar_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个词组的反义词\",\n",
    "    suffix=\"Input: {word}\\nOutput\",\n",
    "    input_variables=[\"word\"],\n",
    ")\n",
    "\n",
    "response = similar_prompt.invoke({\"word\":\"忧郁\"})\n",
    "print(response.text)\n",
    "\n"
   ],
   "id": "dd386c96ff66b89f",
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOpenAIError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 16\u001B[0m\n\u001B[0;32m     12\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBASE_URL\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBASE_URL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     13\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMODEL_EMBEDDING\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMODEL_EMBEDDING\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 16\u001B[0m embeddings_model \u001B[38;5;241m=\u001B[39m \u001B[43mOpenAIEmbeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMODEL_EMBEDDING\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m examples \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# 形容词正反义\u001B[39;00m\n\u001B[0;32m     23\u001B[0m     {\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    108\u001B[0m     }\n\u001B[0;32m    109\u001B[0m ]\n\u001B[0;32m    111\u001B[0m example_selector \u001B[38;5;241m=\u001B[39m SemanticSimilarityExampleSelector\u001B[38;5;241m.\u001B[39mfrom_examples(examples,embeddings_model,FAISS,k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310\\lib\\site-packages\\langchain_openai\\embeddings\\base.py:328\u001B[0m, in \u001B[0;36mOpenAIEmbeddings.validate_environment\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    326\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_client \u001B[38;5;241m=\u001B[39m httpx\u001B[38;5;241m.\u001B[39mClient(proxy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopenai_proxy)\n\u001B[0;32m    327\u001B[0m     sync_specific \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp_client\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_client}\n\u001B[1;32m--> 328\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient \u001B[38;5;241m=\u001B[39m openai\u001B[38;5;241m.\u001B[39mOpenAI(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mclient_params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msync_specific)\u001B[38;5;241m.\u001B[39membeddings  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masync_client:\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopenai_proxy \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_async_client:\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310\\lib\\site-packages\\openai\\_client.py:135\u001B[0m, in \u001B[0;36mOpenAI.__init__\u001B[1;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001B[0m\n\u001B[0;32m    133\u001B[0m     api_key \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m api_key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 135\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OpenAIError(\n\u001B[0;32m    136\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    137\u001B[0m     )\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(api_key):\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mOpenAIError\u001B[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
